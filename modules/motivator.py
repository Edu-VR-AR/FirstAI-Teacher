# modules/motivator.py

# ============================================
# üî• Sprint 6.1 ‚Äî Motivator (Blanchard/Hersey)
# ============================================
from dataclasses import dataclass
from typing import Optional, Dict, Any
import time

# –£—Ä–æ–≤–Ω–∏ –º–æ—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è (S1‚ÄìS4)
LEVEL_NAMES = {
    1: "S1 –ù–æ–≤–∏—á–æ–∫ (–Ω–∏–∑–∫–∞—è –∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å, –≤—ã—Å–æ–∫–∞—è –º–æ—Ç–∏–≤–∞—Ü–∏—è)",
    2: "S2 –£—á–µ–Ω–∏–∫ –≤ –∫—Ä–∏–∑–∏—Å–µ (–Ω–∏–∑–∫–∞—è –∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å, –Ω–∏–∑–∫–∞—è –º–æ—Ç–∏–≤–∞—Ü–∏—è)",
    3: "S3 –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π (–∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å —Å—Ä–µ–¥–Ω—è—è/–≤—ã—Å–æ–∫–∞—è, –º–æ—Ç–∏–≤–∞—Ü–∏—è –∫–æ–ª–µ–±–ª–µ—Ç—Å—è)",
    4: "S4 –°–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–π (–≤—ã—Å–æ–∫–∞—è –∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∏ –º–æ—Ç–∏–≤–∞—Ü–∏—è)"
}

# –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç–∏–ª–∏ (¬´—Å–∏—Ç—É–∞—Ü–∏–æ–Ω–Ω–æ–µ –ª–∏–¥–µ—Ä—Å—Ç–≤–æ¬ª)
LEVEL_STYLES = {
    1: {"style": "–¥–∏—Ä–µ–∫—Ç–∏–≤–Ω—ã–π + –ø–æ–¥–¥–µ—Ä–∂–∫–∞", "tone": "mentor",  "pace": "—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π"},
    2: {"style": "–∫–æ—É—á–∏–Ω–≥ (–º–Ω–æ–≥–æ –ø–æ–¥–¥–µ—Ä–∂–∫–∏)", "tone": "mentor", "pace": "—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π"},
    3: {"style": "–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π –ø–∞—Ä—Ç–Ω—ë—Ä",    "tone": "partner","pace": "–æ–±—ã—á–Ω—ã–π"},
    4: {"style": "–¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ",            "tone": "partner","pace": "—É—Å–∫–æ—Ä–µ–Ω–Ω—ã–π"}
}

def _clamp(x, lo=0.0, hi=1.0):
    return max(lo, min(hi, x))

@dataclass
class MotivationSnapshot:
    level: int
    name: str
    style: Dict[str, Any]
    engagement: float
    confidence: float
    latency_avg_sec: Optional[float]
    signals: Dict[str, Any]  # —á—Ç–æ —Å—Ä–∞–±–æ—Ç–∞–ª–æ
    ts: float

class Motivator(TeachingFunction):
    """
    –ß–∏—Ç–∞–µ—Ç —Å–∏–≥–Ω–∞–ª—ã –∏–∑ context.progress["Expert"] –∏ –≤–µ–¥—ë—Ç motivation_level (1..4).
    –í—ã–¥–∞—ë—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –ø–æ —Å—Ç–∏–ª—é –æ–±—â–µ–Ω–∏—è/—Ç–µ–º–ø—É –∏ —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç ¬´—á—Ç–æ –ø–æ–≤–ª–∏—è–ª–æ¬ª –Ω–∞ –ø–µ—Ä–µ—Ö–æ–¥.
    """

    def __init__(self,
                 th_conf_low=0.38, th_conf_high=0.72,
                 th_eng_low=0.40,  th_eng_high=0.68,
                 th_lat_slow=45.0, th_lat_fast=12.0,
                 hysteresis=0.06):
        # –ü–æ—Ä–æ–≥–∏ –º–æ–∂–Ω–æ —Ç–æ–Ω–∫–æ –ø–æ–¥—Å—Ç—Ä–∞–∏–≤–∞—Ç—å –ø–æ–¥ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—É/—Ä–µ–∂–∏–º
        self.th_conf_low  = th_conf_low
        self.th_conf_high = th_conf_high
        self.th_eng_low   = th_eng_low
        self.th_eng_high  = th_eng_high
        self.th_lat_slow  = th_lat_slow
        self.th_lat_fast  = th_lat_fast
        self.hysteresis   = hysteresis  # —á—Ç–æ–±—ã –Ω–µ ¬´–¥—ë—Ä–≥–∞–ª—Å—è¬ª —É—Ä–æ–≤–µ–Ω—å
        self.last_snapshot: Optional[MotivationSnapshot] = None
        
        self.scenarios = {
            "short_replies": {
                "detect": lambda q, m: q and len(q.split()) <= 3,
                "reaction": "–í–∏–∂—É, —á—Ç–æ –æ—Ç–≤–µ—Ç –ø–æ–ª—É—á–∏–ª—Å—è –∫–æ—Ä–æ—Ç–∫–∏–º. –î–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä—ë–º —á—É—Ç—å –ø–æ–¥—Ä–æ–±–Ω–µ–µ?",
                "style": {"pace": "–∑–∞–º–µ–¥–ª–µ–Ω–Ω—ã–π", "tone": "warm"}
            },
            "frustration": {
                "detect": lambda q, m: q and any(word in q.lower() for word in ["–Ω–µ –ø–æ–Ω–∏–º–∞—é", "—Å–ª–æ–∂–Ω–æ", "—É—Å—Ç–∞–ª", "–Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è"]),
                "reaction": "–≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ —á—É–≤—Å—Ç–≤–æ–≤–∞—Ç—å —Ç—Ä—É–¥–Ω–æ—Å—Ç—å. –ü–æ–ø—Ä–æ–±—É–µ–º —à–∞–≥ –∑–∞ —à–∞–≥–æ–º, —è —Ä—è–¥–æ–º.",
                "style": {"pace": "–∑–∞–º–µ–¥–ª–µ–Ω–Ω—ã–π", "tone": "warm"}
            },
            "slow_response": {
                "detect": lambda q, m: m.get("latency_sec", 0) > 10,
                "reaction": "–ù–µ —Å–ø–µ—à–∏, –¥–∞–≤–∞–π –≤–æ–∑—å–º—ë–º –ø–∞—É–∑—É –∏ —Ä–∞–∑–±–µ—Ä—ë–º —Å–ø–æ–∫–æ–π–Ω–æ.",
                "style": {"pace": "–∑–∞–º–µ–¥–ª–µ–Ω–Ω—ã–π", "tone": "neutral"}
            },
            "low_metrics": {
                "detect": lambda q, m: m.get("engagement", 1) < 0.4 or m.get("confidence", 1) < 0.4,
                "reaction": "–ö–∞–∂–µ—Ç—Å—è, —Å—Ç–∞–ª–æ —Å–ª–æ–∂–Ω–µ–µ —É–¥–µ—Ä–∂–∏–≤–∞—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ. –ß—Ç–æ —Ç–µ–±–µ –ø–æ–º–æ–≥–∞–µ—Ç –æ–±—ã—á–Ω–æ –≤–∫–ª—é—á–∏—Ç—å—Å—è?",
                "style": {"pace": "–æ–±—ã—á–Ω—ã–π", "tone": "supportive"}
            }
        }
        
        # üìå –î–û–ë–ê–í–ò–¢–¨ –í __init__ –ü–û–°–õ–ï self.scenarios (–æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞):
        # –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã: frustration > low_metrics > slow_response > short_replies
        try:
            self.scenario_order = ["frustration", "low_metrics", "slow_response", "short_replies"]
        except AttributeError:
            pass

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
    def _ensure_slot(self, context: Context):
        context.progress.setdefault("Motivator", {})
        slot = context.progress["Motivator"]
        slot.setdefault("level", 1)                  # S1 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        slot.setdefault("history", [])               # –∏—Å—Ç–æ—Ä–∏—è —Å–Ω–∏–º–∫–æ–≤
        slot.setdefault("last_check_ts", time.time())
        return slot

    def _read_expert_metrics(self, context: Context):
        ex = context.progress.get("Expert", {})
        engagement = float(ex.get("engagement", 0.5))
        confidence = float(ex.get("confidence", 0.5))
        lat_avg    = ex.get("latency_avg_sec", None)
        # –£—á—Ç—ë–º —Å—Ç–∞—Ç—É—Å –ø–æ—Å–ª–µ–¥–Ω–µ–π –∑–∞–¥–∞—á–∏ (–µ—Å–ª–∏ Organizer –µ—Å—Ç—å)
        org = context.progress.get("Organizer", {})
        last_task_status = None
        if isinstance(org.get("task_status"), dict):
            # –≤–æ–∑—å–º—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å—Ç–∞—Ç—É—Å, –µ—Å–ª–∏ –µ—Å—Ç—å timestamp ‚Äî —É–ø—Ä–æ—Å—Ç–∏–º: –ø–µ—Ä–≤—ã–π –ø–æ–ø–∞–≤—à–∏–π—Å—è completed/needs_review
            for _tid, st in org["task_status"].items():
                if isinstance(st, dict) and st.get("status") in {"completed","needs_review"}:
                    last_task_status = st.get("status")
                    break
        return engagement, confidence, lat_avg, last_task_status

    def _decide_next_level(self, current_level: int, engagement: float, confidence: float,
                           lat_avg: Optional[float], last_task_status: Optional[str]) -> (int, Dict[str, Any]):
        sig = {"low_conf": False, "low_eng": False, "slow": False, "fast": False, "success": False}

        # –°–∏–≥–Ω–∞–ª—ã
        if confidence < (self.th_conf_low - self.hysteresis):
            sig["low_conf"] = True
        if engagement < (self.th_eng_low - self.hysteresis):
            sig["low_eng"] = True
        if lat_avg is not None and lat_avg > self.th_lat_slow:
            sig["slow"] = True
        if lat_avg is not None and lat_avg < self.th_lat_fast:
            sig["fast"] = True
        if last_task_status == "completed" or confidence > (self.th_conf_high + self.hysteresis):
            sig["success"] = True

        # –õ–æ–≥–∏–∫–∞ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ (–º—è–≥–∫–∞—è; –º–∞–∫—Å–∏–º—É–º –Ω–∞ 1 —à–∞–≥ –∑–∞ –ø—Ä–æ–≤–µ—Ä–∫—É)
        next_level = current_level

        # –ü–æ–Ω–∏–∂–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –ø—Ä–∏ —è–≤–Ω–æ–º —Å–ø–∞–¥–µ
        if sig["low_conf"] or sig["low_eng"] or sig["slow"]:
            next_level = max(1, current_level - 1)

        # –ü–æ–≤—ã—à–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –ø—Ä–∏ —É—Å—Ç–æ–π—á–∏–≤–æ–º —É—Å–ø–µ—Ö–µ/–±—ã—Å—Ç—Ä–æ—Ç–µ
        elif sig["success"] and (engagement > self.th_eng_high or sig["fast"]):
            next_level = min(4, current_level + 1)

        # –ò–Ω–∞—á–µ –æ—Å—Ç–∞—ë–º—Å—è –Ω–∞ –º–µ—Å—Ç–µ (–≥–∏—Å—Ç–µ—Ä–µ–∑–∏—Å)
        return next_level, sig

    def process(self, context: Context) -> dict:
        """ –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (–º–æ–∂–Ω–æ –≤—ã–∑—ã–≤–∞—Ç—å –Ω–∞ —Å–æ–±—ã—Ç–∏—è—Ö inactivity, tick, end –∏ —Ç.–ø.) """
        return self._evaluate(context, event="tick")

    def observe(self, event: str, context: Context, question: Optional[str]=None, answer: Optional[dict]=None) -> dict:
        """ –í—ã–∑—ã–≤–∞—Ç—å –ø–æ—Å–ª–µ –∑–Ω–∞—á–∏–º—ã—Ö —Å–æ–±—ã—Ç–∏–π: student_question, student_submit, inactivity, end """
        return self._evaluate(context, event=event, question=question, answer=answer)
    
    
    def _pick_motivation(self, level: int) -> Dict[str, str]:
        """–í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—É—é —Ñ—Ä–∞–∑—É –∏ —á–µ–ª–ª–µ–Ω–¥–∂ –¥–ª—è —É—Ä–æ–≤–Ω—è."""
        lib = MOTIVATION_LIBRARY.get(level, MOTIVATION_LIBRARY[1])
        phrase = random.choice(lib["phrases"])
        challenge = random.choice(lib["challenges"])
        return {"phrase": phrase, "challenge": challenge}
    
    #####
    def record_reflection_answer(self, context: Context, text: str):
        """–§–∏–∫—Å–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —Å—Ç—É–¥–µ–Ω—Ç–∞ –Ω–∞ —Ä–µ—Ñ–ª–µ–∫—Å–∏–≤–Ω—ã–π –≤–æ–ø—Ä–æ—Å"""
        store = context.progress.setdefault("Reflection", {})
        store.setdefault("answers", []).append({"ts": time.time(), "text": text})

        # üîπ –ø—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–∫—Ü–∏—è-–ø—Ä–∏–º–µ—Ä: –µ—Å–ª–∏ —Å—Ç—É–¥–µ–Ω—Ç –ø–∏—à–µ—Ç "–≤—Ä–µ–º–µ–Ω–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç"
        if "–≤—Ä–µ–º" in text.lower():
            context.progress["Motivator"].setdefault("last", {}).setdefault("style", {})["pace"] = "–∑–∞–º–µ–¥–ª–µ–Ω–Ω—ã–π"

        return {"status": "recorded", "answer": text}
    #####

    def _evaluate(self, context: Context, event: str, question: Optional[str]=None, answer: Optional[dict]=None) -> dict:
        slot = self._ensure_slot(context)

        # 1) –ß–∏—Ç–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –æ—Ç Expert/Organizer
        engagement, confidence, lat_avg, last_task_status = self._read_expert_metrics(context)

        # 2) –†–µ—à–∞–µ–º –ø—Ä–æ —É—Ä–æ–≤–µ–Ω—å
        current_level = int(slot.get("level", 1))
        next_level, signals = self._decide_next_level(current_level, engagement, confidence, lat_avg, last_task_status)

        # 3) –û–±–Ω–æ–≤–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å –∏ —Å–æ–±–∏—Ä–∞–µ–º —Å–Ω–∏–º–æ–∫
        slot["level"] = next_level
        snap = MotivationSnapshot(
            level=next_level,
            name=LEVEL_NAMES[next_level],
            style=LEVEL_STYLES[next_level],
            engagement=_clamp(engagement), confidence=_clamp(confidence),
            latency_avg_sec=lat_avg, signals=signals, ts=time.time()
        )
        self.last_snapshot = snap
        # –õ—ë–≥–∫–∞—è –∏—Å—Ç–æ—Ä–∏—è (—Ö—Ä–∞–Ω–∏—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20)
        hist = slot["history"]
        hist.append({
            "ts": snap.ts,
            "event": event,
            "level": snap.level,
            "name": snap.name,
            "style": snap.style,
            "engagement": snap.engagement,
            "confidence": snap.confidence,
            "latency_avg_sec": snap.latency_avg_sec,
            "signals": snap.signals,
            "q": question,
        })
        slot["history"] = hist[-20:]
        slot["last_check_ts"] = snap.ts
        
        # üîπ 6.3: –≤—ã–±–∏—Ä–∞–µ–º –º–æ—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω—É—é —Ñ—Ä–∞–∑—É –∏ —á–µ–ª–ª–µ–Ω–¥–∂ –ø–æ —É—Ä–æ–≤–Ω—é (—Å —Ä–∞–Ω–¥–æ–º–∏–∑–∞—Ü–∏–µ–π)
        lib = MOTIVATION_LIBRARY.get(next_level, MOTIVATION_LIBRARY[1])
        mot_phrase = random.choice(lib["phrases"])
        mot_challenge = random.choice(lib["challenges"])
        motivation = {"phrase": mot_phrase, "challenge": mot_challenge}

        # 4) –†–µ–∑—É–ª—å—Ç–∞—Ç + —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å—Ç–∏–ª—é/—Ç–µ–º–ø—É/—Ç–æ–Ω—É
        result = {
            "level": snap.level,
            "level_name": snap.name,
            "style": snap.style,               # {'style','tone','pace'}
            "metrics": {
                "engagement": snap.engagement,
                "confidence": snap.confidence,
                "latency_avg_sec": snap.latency_avg_sec
            },
            "signals": signals,
            "motivation": motivation           # üîπ –¥–æ–±–∞–≤–∏–ª–∏
        }
        context.progress["Motivator"]["last"] = result
        
        # 5) –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –ø–∞–¥–µ–Ω–∏—è –º–æ—Ç–∏–≤–∞—Ü–∏–∏ (6.2)
        question_text = question or ""
        metrics_for_rules = {
            "latency_sec": (context.progress.get("Expert", {}) or {}).get("latency_sec", 0),
            "engagement": engagement,
            "confidence": confidence
        }
        reaction = None
        style_update = None
        triggered = []
        
        for name, data in self.scenarios.items():
            try:
                if data["detect"](question_text, metrics_for_rules):
                    triggered.append(name)
                    reaction = data["reaction"]
                    style_update = data["style"]
                    # –≤–µ–¥—ë–º —Å—á—ë—Ç—á–∏–∫ —ç–ø–∏–∑–æ–¥–æ–≤
                    slot["drop_count"] = slot.get("drop_count", 0) + 1
                    break  # —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Å—Ü–µ–Ω–∞—Ä–∏–π –∑–∞ —Ä–∞–∑
            except Exception:
                continue
        
        # –≤–∫–ª—é—á–∞–µ–º –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result.update({
            "triggered": triggered,
            "reaction": reaction,
            "style_update": style_update,
            "drop_count": slot.get("drop_count", 0)
        })
        
         # üîπ 6.4 –ú–∏–Ω–∏-—Ä–µ—Ñ–ª–µ–∫—Å–∏—è
        need_reflection = False
        if slot.get("drop_count", 0) >= 3 or (signals.get("low_conf") and signals.get("low_eng")):
            need_reflection = True

        reflection_q = None
        if need_reflection:
            reflection_q = random.choice(REFLECTION_QUESTIONS)
            # —Å–æ—Ö—Ä–∞–Ω–∏–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∏—Å—Ç–æ—Ä–∏—é –≤–æ–ø—Ä–æ—Å–æ–≤
            context.progress.setdefault("Reflection", {})
            context.progress["Reflection"].setdefault("asked", []).append({
                "ts": snap.ts,
                "question": reflection_q,
                "triggered_by": triggered or signals
            })
            
        #####    
        # –ø–æ—Å–ª–µ –≤—ã–±–æ—Ä–∞ reflection_q
        asked = context.progress.setdefault("Reflection", {}).setdefault("asked", [])
        last_q = asked[-1]["question"] if asked else None
        if last_q == reflection_q:
            pool = [q for q in REFLECTION_QUESTIONS if q != last_q] or REFLECTION_QUESTIONS
            reflection_q = random.choice(pool)
        asked.append({"ts": snap.ts, "question": reflection_q, "triggered_by": triggered or signals})
        #####

        result["reflection_question"] = reflection_q
        
        return result