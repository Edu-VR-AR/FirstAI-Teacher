# core/__init__.py

import os
import glob

from typing import List
from pathlib import Path

from datetime import datetime

import re

def extract_knowledge_types(docs: list) -> dict:
    facts = []
    procedures = []
    meta = []

    for doc in docs:
        sentences = re.split(r'[.!?]', doc)  # –ø—Ä–æ—Å—Ç–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        for sent in sentences:
            s = sent.lower().strip()
            if any(trigger in s for trigger in FACT_TRIGGERS):
                facts.append(sent.strip())
            elif any(trigger in s for trigger in PROCEDURE_TRIGGERS):
                procedures.append(sent.strip())
            elif any(trigger in s for trigger in META_TRIGGERS):
                meta.append(sent.strip())

    return {
        "facts": facts[:5],        # –æ–≥—Ä–∞–Ω–∏—á–∏–º –ø–æ 5 –ø—Ä–∏–º–µ—Ä–æ–≤
        "procedures": procedures[:5],
        "meta": meta[:5]
    }

def start_task(context: Context, task_id: str):
    for task in context.progress.get("Organizer", {}).get("tasks", []):
        if task["id"] == task_id:
            task["start_time"] = datetime.now().isoformat()
            task["is_completed"] = False
            print(f"‚ñ∂Ô∏è –ó–∞–¥–∞–Ω–∏–µ {task_id} –Ω–∞—á–∞—Ç–æ.")
            return

def mark_task_complete(context: Context, task_id: str):
    for task in context.progress.get("Organizer", {}).get("tasks", []):
        if task["id"] == task_id:
            end_time = datetime.now()
            task["end_time"] = end_time.isoformat()
            if task["start_time"]:
                start_time = datetime.fromisoformat(task["start_time"])
                task["duration_sec"] = (end_time - start_time).total_seconds()
            else:
                task["duration_sec"] = None
            task["is_completed"] = True
            print(f"‚úÖ –ó–∞–¥–∞–Ω–∏–µ {task_id} –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
            return

def update_task_status(context: Context, task_id: str, status: str, answer: str = None):
    if status not in ["not_started", "in_progress", "completed", "needs_review"]:
        print(f"‚ö†Ô∏è –ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π —Å—Ç–∞—Ç—É—Å: {status}")
        return

    for task in context.progress.get("Organizer", {}).get("tasks", []):
        if task["id"] == task_id:
            task["status"] = status
            if answer:
                task["student_answer"] = answer
            print(f"üìå –û–±–Ω–æ–≤–ª—ë–Ω —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞–Ω–∏—è {task_id} ‚Üí {status}")
            return

from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np

from nltk.corpus import stopwords
import nltk

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –æ–¥–∏–Ω —Ä–∞–∑
nltk.download('stopwords')

# –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Ä—É—Å—Å–∫–∏—Ö —Å—Ç–æ–ø-—Å–ª–æ–≤
russian_stopwords = stopwords.words("russian")
russian_stopwords.extend(['—ç—Ç–æ', '–Ω–µ—é'])  # —Ç–≤–æ–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞

class KnowledgeBase:
    def __init__(self):
        self.docs = []
        self.doc_names = []
        self.vectorizer = None
        self.doc_vectors = None

    def load(self, discipline: str):
        self.docs = load_documents(discipline)
        self.doc_names = [f"doc_{i+1}" for i in range(len(self.docs))]
        if not self.docs:
            print("‚ö†Ô∏è –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø—É—Å—Ç–∞")
            return
        

        
        self.vectorizer = TfidfVectorizer(stop_words=russian_stopwords)
        self.doc_vectors = self.vectorizer.fit_transform(self.docs)
        print(f"‚úÖ –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {len(self.docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–µ '{discipline}'.")

    def search(self, query: str, top_k: int = 2):
        if not self.doc_vectors is None:
            query_vec = self.vectorizer.transform([query])
            scores = np.dot(query_vec, self.doc_vectors.T).toarray()[0]
            top_indices = np.argsort(scores)[::-1][:top_k]
            return [(self.docs[i], self.doc_names[i], scores[i]) for i in top_indices]
        else:
            return []

# --- intents: –¥–µ—Ç–µ–∫—Ç–æ—Ä —Ç–∏–ø–æ–≤ –≤–æ–ø—Ä–æ—Å–æ–≤
import re
from typing import List, Dict

INTENT_PATTERNS: Dict[str, List[str]] = {
    "why": [r"\b–ø–æ—á–µ–º—É\b", r"\b–∑–∞—á–µ–º\b", r"\b–ø–æ –∫–∞–∫–æ–π –ø—Ä–∏—á–∏–Ω–µ\b"],
    "how": [r"\b–∫–∞–∫\b", r"\b–∫–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º\b", r"\b–ø–æ—Ä—è–¥–æ–∫\b", r"\b—à–∞–≥(–∏|–æ–≤)\b"],
    "what_if": [r"\b—á—Ç–æ –µ—Å–ª–∏\b", r"\b–∞ –µ—Å–ª–∏\b"],
    "examples": [r"\b–ø—Ä–∏–º–µ—Ä(—ã)?\b", r"\b–∫–µ–π—Å—ã?\b", r"\b–∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏(—è|–∏)\b"]
}

def detect_intents(question: str) -> List[str]:
    q = question.lower()
    hits = [intent for intent, pats in INTENT_PATTERNS.items() if any(re.search(p, q) for p in pats)]
    if not hits:
        if q.startswith("—á—Ç–æ —Ç–∞–∫–æ–µ"):
            hits = ["examples"]
        else:
            hits = ["how"]
    return hits

# --- —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –ø–æ —Ç–∏–ø–∞–º
def _format_by_intents(answer_base: str, intents: List[str]) -> str:
    sections = []
    for it in intents:
        if it == "why":
            sections.append(
                "–ü–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ:\n"
                "- –°–≤—è–∑—å —Å —Ü–µ–ª—è–º–∏ –∑–∞–Ω—è—Ç–∏—è\n"
                "- –ö–∞–∫–∏–µ –æ—à–∏–±–∫–∏ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç\n"
                "- –ö–∞–∫ –≤–ª–∏—è–µ—Ç –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç"
            )
        elif it == "how":
            sections.append(
                "–ö–∞–∫ –¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å (—à–∞–≥–∏):\n"
                "1) –ò–∑—É—á–∏—Ç–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è\n"
                "2) –ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –¥–∞–Ω–Ω—ã–µ/–º–∞–∫–µ—Ç\n"
                "3) –ü—Ä–∏–º–µ–Ω–∏—Ç–µ –ø—Ä–∞–≤–∏–ª–∞ –∏–∑ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤\n"
                "4) –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞"
            )
        elif it == "what_if":
            sections.append(
                "–ß—Ç–æ –µ—Å–ª–∏ (—Ä–∞–∑–±–æ—Ä –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤):\n"
                "- –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–∞–ª–æ ‚Üí –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω—É—é —Å—Ö–µ–º—É\n"
                "- –ï—Å–ª–∏ –∞—É–¥–∏—Ç–æ—Ä–∏—è –Ω–µ —ç–∫—Å–ø–µ—Ä—Ç–Ω–∞—è ‚Üí —É–ø—Ä–æ—â–∞–π—Ç–µ –ø–æ–¥–ø–∏—Å–∏\n"
                "- –ï—Å–ª–∏ —Ñ–æ—Ä–º‚Äë—Ñ–∞–∫—Ç–æ—Ä —É–∑–∫–∏–π ‚Üí –∏–∑–±–µ–≥–∞–π—Ç–µ –ø–µ—Ä–µ–≥—Ä—É–∑–∞"
            )
        elif it == "examples":
            sections.append(
                "–ü—Ä–∏–º–µ—Ä—ã/–∫–µ–π—Å—ã:\n"
                "- –û–¥–Ω–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–∞—è –∏–Ω—Ñ–æ–≥—Ä–∞—Ñ–∏–∫–∞ –¥–ª—è –æ—Ç—á—ë—Ç–∞\n"
                "- –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏\n"
                "- –ü–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —É—á–µ–±–Ω–æ–≥–æ –ø–ª–∞–∫–∞—Ç–∞"
            )
    return f"{answer_base}\n\n" + ("\n\n".join(sections) if sections else "")

# --- –¥–µ—Ç–µ–∫—Ç–æ—Ä —É—Ä–æ–≤–Ω—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ –≤–æ–ø—Ä–æ—Å–µ
import re

def detect_detail_level(question: str) -> str:
    q = question.lower()
    if re.search(r"\b(–∫—Ä–∞—Ç–∫–æ|–∫–æ—Ä–æ—Ç–∫–æ|–≤ –¥–≤—É—Ö —Å–ª–æ–≤–∞—Ö)\b", q):
        return "short"
    if re.search(r"\b(–ø–æ–¥—Ä–æ–±–Ω–æ|—Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ|–¥–µ—Ç–∞–ª—å–Ω–æ)\b", q):
        return "long"
    return "short"  # –¥–µ—Ñ–æ–ª—Ç

# --- ¬´–∫—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞¬ª –∏–∑ –±–∞–∑–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
def make_brief(text: str, limit: int = 300) -> str:
    t = text.strip().replace("\n\n", "\n")
    return (t[:limit] + "‚Ä¶") if len(t) > limit else t

# --- —Ñ–æ—Ä–º–∏—Ä—É–µ–º explanation-—Å–µ–∫—Ü–∏–∏ –ø–æ intents (–∏—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –∏–º–µ—é—â–∏–π—Å—è _format_by_intents)
def make_explanation(answer_base: str, intents: list, detail: str) -> str:
    # –±–µ—Ä—ë–º –Ω–∞—à –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä –∏–∑ 4.2
    expl = _format_by_intents("", intents).strip()
    if detail == "long":
        # –¥–ª—è ¬´long¬ª –¥–æ–±–∞–≤–∏–º –±–∞–∑–æ–≤—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∫–∞–∫ lead-in
        return f"{answer_base}\n\n{expl}" if expl else answer_base
    else:
        # –¥–ª—è ¬´short¬ª —Ç–æ–ª—å–∫–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏ –ø–æ –Ω–∞–º–µ—Ä–µ–Ω–∏—è–º
        return expl or "–ö–ª—é—á–µ–≤–∞—è –º—ã—Å–ª—å: —Å–º. –æ—Å–Ω–æ–≤–Ω—É—é —á–∞—Å—Ç—å –æ—Ç–≤–µ—Ç–∞."

# --- —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–æ–≤
def build_next_steps(intents: list, context: Context) -> list:
    steps = []
    # –ø–æ–¥—Å–∫–∞–∑–∫–∞ –ø–µ—Ä–µ–π—Ç–∏ –∫ –¥–µ–π—Å—Ç–≤–∏—é, –µ—Å–ª–∏ –µ—Å—Ç—å Organizer.tasks
    org = context.progress.get("Organizer", {})
    tasks = org.get("tasks", [])
    action_tasks = [t for t in tasks if t.get("type") in ("action", "text", "reflection")]
    if action_tasks:
        steps.append(f"–í—ã–ø–æ–ª–Ω–∏ –∑–∞–¥–∞–Ω–∏–µ: ¬´{action_tasks[0]['instruction']}¬ª")
    # –æ–±—â–∏–µ –≤–µ—Ç–≤–ª–µ–Ω–∏—è –ø–æ –Ω–∞–º–µ—Ä–µ–Ω–∏—è–º
    if "how" in intents:
        steps.append("–°–≤–µ—Ä—å—Å—è —Å —á–µ–∫-–ª–∏—Å—Ç–æ–º –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –∑–∞–Ω—è—Ç–∏—è.")
    if "why" in intents:
        steps.append("–í—ã–¥–µ–ª–∏ 2‚Äì3 –∞—Ä–≥—É–º–µ–Ω—Ç–∞, –ø–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ –∏–º–µ–Ω–Ω–æ –¥–ª—è —Ç–≤–æ–µ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏.")
    if "examples" in intents:
        steps.append("–ù–∞–π–¥–∏ 2 –ø—Ä–∏–º–µ—Ä–∞ –∏–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ –∫—Ä–∞—Ç–∫–æ —Å—Ä–∞–≤–Ω–∏ –∏—Ö.")
    if "what_if" in intents:
        steps.append("–û–ø–∏—à–∏ 1‚Äì2 –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –¥–ª—è —Ç–≤–æ–µ–≥–æ –∫–µ–π—Å–∞ –∏ –≤—ã–±–µ—Ä–∏ –ø–æ–¥—Ö–æ–¥—è—â—É—é.")
    # –∑–∞–ø–∞—Å–Ω–æ–π –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —à–∞–≥
    if not steps:
        steps.append("–ó–∞–¥–∞–π —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –ø–µ—Ä–µ–π–¥–∏ –∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é –±–ª–∏–∂–∞–π—à–µ–≥–æ –∑–∞–¥–∞–Ω–∏—è.")
    return steps

# =========================
# üß© Sprint 5.2 ‚Äî Signals
# =========================
from datetime import datetime, timedelta

# 1) –û–±—ä–µ–∫—Ç–∏–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –∏–∑ Organizer + –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ñ—Ä—É—Å—Ç—Ä–∞—Ü–∏–∏
def detect_objective_situation(context: Context) -> str:
    org = context.progress.get("Organizer", {})
    status_map = org.get("task_status", {})  # –æ–∂–∏–¥–∞–µ—Ç—Å—è {task_id: {"status": "...", "is_completed": bool, ...}}

    # 1) —É—Å–ø–µ—Ö: –µ—Å—Ç—å –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
    has_completed = any(v.get("status") in {"completed"} or v.get("is_completed") for v in status_map.values())
    if has_completed:
        return "success"

    # 2) –æ—à–∏–±–∫–∞/–Ω—É–∂–µ–Ω —Ä–∞–∑–±–æ—Ä: –µ—Å—Ç—å –∑–∞–¥–∞—á–∏ —Å needs_review/error
    has_issue = any(v.get("status") in {"needs_review", "error"} for v in status_map.values())
    if has_issue:
        return "error"

    # 3) —Ñ—Ä—É—Å—Ç—Ä–∞—Ü–∏—è: —á–∞—Å—Ç—ã–µ –∫–æ—Ä–æ—Ç–∫–∏–µ —É—Ç–æ—á–Ω–µ–Ω–∏—è –∏–ª–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –¥–æ–ª–≥–∞—è –ø–∞—É–∑–∞
    hist = context.progress.get("Expert", {}).get("dialog_history", [])
    if len(hist) >= 3:
        last3 = [h.get("question", "").lower() for h in hist[-3:]]
        short_count = sum(len(q.split()) <= 4 for q in last3)
        if short_count >= 2:  # –¥–≤–∞ –∫–æ—Ä–æ—Ç–∫–∏—Ö —É—Ç–æ—á–Ω–µ–Ω–∏—è –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ç—Ä—ë—Ö
            return "frustration"

    # (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –¥–æ–ª–≥–∞—è –ø–∞—É–∑–∞: –µ—Å–ª–∏ —É —Ç–µ–±—è –≥–¥–µ-—Ç–æ —Ö—Ä–∞–Ω–∏—Ç—Å—è timestamp –ø–æ—Å–ª–µ–¥–Ω–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ ‚Äî –º–æ–∂–Ω–æ —É—á–µ—Å—Ç—å
    # last_time = context.progress.get("last_activity_ts")
    # if last_time and (datetime.utcnow() - last_time) > timedelta(minutes=15):
    #     return "frustration"

    return "start"

# 2) –°–º–µ—à–∏–≤–∞–Ω–∏–µ: –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –æ–±—ä–µ–∫—Ç–∏–≤–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–∞–¥ —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ (–∏–∑ 5.1 ‚Äî detect_situation)
def detect_situation_mixed(user_text: str, context: Context) -> str:
    state_signal = detect_objective_situation(context)
    if state_signal != "start":
        return state_signal
    # –µ—Å–ª–∏ –æ–±—ä–µ–∫—Ç–∏–≤–Ω—ã—Ö –Ω–µ—Ç ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä (–∏–∑ 5.1)
    return detect_situation(user_text)

# 3) –ü–∞—Ç—á RelationalTuner.embellish: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–º–µ—à–∞–Ω–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä
#    (–∫–ª–∞—Å—Å RelationalTuner —É–∂–µ –æ–±—ä—è–≤–ª–µ–Ω —Ä–∞–Ω–µ–µ ‚Äî –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏–º —Ç–æ–ª—å–∫–æ –º–µ—Ç–æ–¥)
def _rt_embellish_patched(self,
                          answer_data: dict,
                          context: Context,
                          user_text: str = None,
                          tone_override: str = None,
                          position: str = None) -> dict:
    tone = tone_override or self.default_tone
    pos = position or self.position

    # –∫–ª—é—á–µ–≤–∞—è –∑–∞–º–µ–Ω–∞:
    situation = detect_situation_mixed(user_text or answer_data.get("question", ""), context)

    chosen = pick_empathy_line(context, situation, tone)
    intro, outro = None, None

    if pos == "auto":
        if situation in {"error", "doubt", "frustration", "help_request"}:
            intro = chosen["phrase"]
        elif situation in {"success", "end"}:
            outro = chosen["phrase"]
        else:
            intro = chosen["phrase"]
    elif pos == "intro":
        intro = chosen["phrase"]
    elif pos == "outro":
        outro = chosen["phrase"]
    elif pos == "both":
        intro = chosen["phrase"]
        outro = pick_empathy_line(context, situation, tone)["phrase"]

    # —Å–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
    full_text = ""
    if intro:
        full_text += intro + "\n\n"
    full_text += answer_data.get("answer", "")
    if outro:
        full_text += "\n\n" + outro

    # –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è UI/–ª–æ–≥–∏–∫–∏
    answer_data["empathy"] = {
        "situation": chosen["situation"],
        "tone": chosen["tone"],
        "intro": intro,
        "outro": outro
    }
    answer_data["answer_empathic"] = full_text
    return answer_data

# –ø—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—á
RelationalTuner.embellish = _rt_embellish_patched

print("‚úÖ Sprint 5.2: objective signals integrated into RelationalTuner.embellish")

# ================================
# üß© Patch: Empathy inside Expert
# ================================
import random

# 0) –°—Ç—Ä–∞—Ö–æ–≤–∫–∞: –µ—Å–ª–∏ —Ç—é–Ω–µ—Ä –µ—â—ë –Ω–µ —Å–æ–∑–¥–∞–Ω ‚Äî —Å–æ–∑–¥–∞–¥–∏–º
try:
    tuner
except NameError:
    try:
        tuner = RelationalTuner(default_tone="warm", position="auto")
    except NameError:
        # –µ—Å–ª–∏ –∫–ª–∞—Å—Å –µ—â—ë –Ω–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω ‚Äî –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–≥–ª—É—à–∫–∞,
        # –Ω–æ –≤ —Ç–≤–æ—ë–º –ø—Ä–æ–µ–∫—Ç–µ RelationalTuner —É–∂–µ –µ—Å—Ç—å –∏–∑ 5.1
        class _DummyTuner:
            def embellish(self, answer_data, context, user_text=None, tone_override=None, position=None):
                # –±–µ–∑ —Ç—é–Ω–µ—Ä–∞ –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
                answer_data["answer_empathic"] = answer_data.get("answer", "")
                answer_data["empathy"] = {
                    "situation": "start", "tone": "warm", "intro": None, "outro": None
                }
                return answer_data
        tuner = _DummyTuner()

# 1) –°—Ç—Ä–∞—Ö–æ–≤–∫–∞: —Å–º–µ—à–∞–Ω–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä —Å–∏—Ç—É–∞—Ü–∏–π (–∏–∑ 5.2). –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî fallback –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–π.
def _detect_situation_for_empathy(user_text: str, context: 'Context') -> str:
    try:
        return detect_situation_mixed(user_text, context)  # –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –æ–±—ä–µ–∫—Ç–∏–≤–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
    except NameError:
        try:
            return detect_situation(user_text)  # —Ç–µ–∫—Å—Ç–æ–≤—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä –∏–∑ 5.1
        except NameError:
            return "start"

# 2) –ü–∞—Ç—á–∏–º —Ç–æ–ª—å–∫–æ ¬´—Ö–≤–æ—Å—Ç¬ª Expert.respond: –ø–æ—Å–ª–µ —Å–±–æ—Ä–∫–∏ answer_data ‚Üí –¥–æ–±–∞–≤–ª—è–µ–º —ç–º–ø–∞—Ç–∏—é
_old_respond = Expert.respond

def _respond_with_empathy(self, question: str, context: 'Context') -> dict:
    # –≤—ã–∑—ã–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é (—Å RAG, –ø–∞–º—è—Ç—å—é, —Ç–æ–Ω–æ–º/—É—Ä–æ–≤–Ω–µ–º –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ 5.4)
    answer_data = _old_respond(self, question, context)

    # –µ—Å–ª–∏ —ç—Ç–æ —Å–±—Ä–æ—Å –ø–∞–º—è—Ç–∏ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∫—Ä–∞—à–µ–Ω–∏–µ
    if isinstance(answer_data, dict) and answer_data.get("status") == "dialog_cleared":
        return answer_data

    # —ç–º–ø–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±–≤—è–∑–∫–∞
    # (–ø–æ–∑–∏—Ü–∏—è —Ç—é–Ω–µ—Ä–∞ —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞, –Ω–æ –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç—É—Ç: position="intro"/"outro"/"both")
    try:
        enriched = tuner.embellish(
            answer_data,
            context,
            user_text=question,                 # –≤–∞–∂–Ω–æ: –¥–µ—Ç–µ–∫—Ü–∏—è —Å–∏—Ç—É–∞—Ü–∏–∏ –±–µ—Ä—ë—Ç –∏–º–µ–Ω–Ω–æ —Ä–µ–ø–ª–∏–∫—É —Å—Ç—É–¥–µ–Ω—Ç–∞
            tone_override=None,                 # –º–æ–∂–Ω–æ –ø–æ–¥–º–µ–Ω–∏—Ç—å –Ω–∞ context.tone –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏
            position=None                       # None ‚Üí –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–ª–∏—Ç–∏–∫—É —Ç—é–Ω–µ—Ä–∞ ("auto")
        )
    except Exception:
        # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –Ω–µ –ª–æ–º–∞–µ–º –æ—Ç–≤–µ—Ç
        enriched = answer_data
        enriched.setdefault("answer_empathic", enriched.get("answer", ""))
        enriched.setdefault("empathy", {"situation": _detect_situation_for_empathy(question, context),
                                        "tone": "warm", "intro": None, "outro": None})

    # –æ–±–Ω–æ–≤–∏–º last_answer –≤ –∏—Å—Ç–æ—Ä–∏–∏ (—á—Ç–æ–±—ã UI –≤–∏–¥–µ–ª –æ–±–æ–≥–∞—â—ë–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç)
    try:
        context.progress["Expert"]["last_answer"] = enriched
        # —Å–æ—Ö—Ä–∞–Ω–∏–º –µ—â—ë –∏ ¬´–ø–æ—Å–ª–µ–¥–Ω—é—é —ç–º–ø–∞—Ç–∏—é¬ª –≤ —Ç—é–Ω–µ—Ä–µ (—É–¥–æ–±–Ω–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏/UI)
        context.progress.setdefault("RelationalTuner", {})
        context.progress["RelationalTuner"]["last"] = enriched.get("empathy")
    except Exception:
        pass

    return enriched

# –ø—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—á
Expert.respond = _respond_with_empathy

print("‚úÖ Empathy integrated: Expert.respond —Ç–µ–ø–µ—Ä—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç answer_empathic + empathy")

# ==========================================
# ‚è± Patch: latency/tempo for Expert (Sprint 5.4+)
# ==========================================
import time
from collections import deque

# –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ‚Äî –º–æ–∂–Ω–æ –ø–æ–¥–ø—Ä–∞–≤–∏—Ç—å –ø–æ–¥ —Å–µ–±—è
LAT_FAST_SEC   = 12.0   # –±—ã—Å—Ç—Ä–µ–µ —ç—Ç–æ–≥–æ ‚Äî —Å—á–∏—Ç–∞–µ–º "–≤—ã—Å–æ–∫–∞—è –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å"
LAT_SLOW_SEC   = 45.0   # –º–µ–¥–ª–µ–Ω–Ω–µ–µ —ç—Ç–æ–≥–æ ‚Äî "–Ω–∏–∑–∫–∞—è –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å"
LAT_WINDOW_N   = 8      # —Å–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ —Å—Ä–µ–¥–Ω–∏—Ö
DELTA_ENG_FAST = +0.06  # –Ω–∞—Å–∫–æ–ª—å–∫–æ –º–µ–Ω—è—Ç—å engagement –∑–∞ –±—ã—Å—Ç—Ä—ã–π –æ—Ç–≤–µ—Ç
DELTA_ENG_SLOW = -0.06  # –Ω–∞—Å–∫–æ–ª—å–∫–æ –º–µ–Ω—è—Ç—å engagement –∑–∞ –º–µ–¥–ª–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
DELTA_CONF_UP  = +0.05  # –ø–æ–ø—Ä–∞–≤–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∑–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ —É–≤–µ—Ä–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã
DELTA_CONF_DN  = -0.07  # –ø–æ–ø—Ä–∞–≤–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∑–∞ —Å–æ–º–Ω–µ–Ω–∏–µ/–¥–æ–ª–≥—É—é –ø–∞—É–∑—É

# —Å—Ç—Ä–∞—Ö—É–µ–º: –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±—É—Ñ–µ—Ä–∞ –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–µ–π –æ–¥–∏–Ω —Ä–∞–∑ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
def _ensure_latency_buffer(context: 'Context'):
    context.progress.setdefault("Expert", {})
    if "latency_buffer" not in context.progress["Expert"]:
        context.progress["Expert"]["latency_buffer"] = deque(maxlen=LAT_WINDOW_N)

# –ø–∞—Ç—á–∏–º Expert.respond ‚Äî –ø–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ–º ¬´—Ö–≤–æ—Å—Ç¬ª
_old_expert_respond_latency = Expert.respond

def _respond_with_latency(self, question: str, context: 'Context') -> dict:
    # 1) –¥–æ –≤—ã–∑–æ–≤–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ ‚Äî –∏–∑–º–µ—Ä—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É
    now = time.time()
    # –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –ø–æ–ª—è
    context.progress.setdefault("Expert", {})
    last_ts = context.progress["Expert"].get("last_interaction_time", None)
    latency = None
    if last_ts is not None:
        latency = max(0.0, now - last_ts)
    # –æ–±–Ω–æ–≤–∏–º last_interaction_time —Å—Ä–∞–∑—É ‚Äî —á—Ç–æ–±—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –Ω–µ —Å–±–∏–≤–∞–ª–∏
    context.progress["Expert"]["last_interaction_time"] = now

    # 2) –≤—ã–∑—ã–≤–∞–µ–º ¬´—Å—Ç–∞—Ä—ã–π¬ª respond (–≤–Ω—É—Ç—Ä–∏ –æ–Ω —É–∂–µ –æ–±–Ω–æ–≤–∏—Ç engagement/confidence –ø–æ —Å–≤–æ–∏–º –ø—Ä–∞–≤–∏–ª–∞–º)
    answer = _old_expert_respond_latency(self, question, context)

    # 3) –µ—Å–ª–∏ —ç—Ç–æ —Å–±—Ä–æ—Å –ø–∞–º—è—Ç–∏ ‚Äî –≤—ã—Ö–æ–¥–∏–º –∫–∞–∫ –µ—Å—Ç—å
    if isinstance(answer, dict) and answer.get("status") == "dialog_cleared":
        return answer

    # 4) –¥–æ–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–µ—Ç—Ä–∏–∫ —Å —É—á—ë—Ç–æ–º latency (–º—è–≥–∫–æ–µ –≤–ª–∏—è–Ω–∏–µ + –æ–∫–Ω–æ)
    _ensure_latency_buffer(context)
    buf: deque = context.progress["Expert"]["latency_buffer"]
    if latency is not None:
        buf.append(latency)

        # –±–∞–∑–æ–≤–∞—è –ø–æ–ø—Ä–∞–≤–∫–∞ –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç–∏
        eng = context.progress["Expert"].get("engagement", 0.5)
        if latency <= LAT_FAST_SEC:
            eng += DELTA_ENG_FAST
        elif latency >= LAT_SLOW_SEC:
            eng += DELTA_ENG_SLOW
        # –∫–ª–∏–ø–ø–∏–Ω–≥
        eng = min(max(eng, 0.0), 1.0)
        context.progress["Expert"]["engagement"] = eng

        # –ª—ë–≥–∫–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–µ –ø–∞—É–∑—ã —Å–ª–µ–≥–∫–∞ ¬´—Ä–æ–Ω—è—é—Ç¬ª —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        conf = context.progress["Expert"].get("confidence", 0.5)
        if latency >= LAT_SLOW_SEC * 1.5:
            conf += DELTA_CONF_DN/2
        elif latency <= LAT_FAST_SEC/2:
            conf += DELTA_CONF_UP/2
        conf = min(max(conf, 0.0), 1.0)
        context.progress["Expert"]["confidence"] = conf

    # 5) –¥–æ–±–∞–≤–ª—è–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è –≤ –æ—Ç–≤–µ—Ç
    avg = (sum(context.progress["Expert"]["latency_buffer"]) / len(context.progress["Expert"]["latency_buffer"])
           if context.progress["Expert"]["latency_buffer"] else None)
    answer["latency_sec"] = latency
    answer["latency_avg_sec"] = avg

    # 6) –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–Ω–æ –∞–≤—Ç–æ–ø–æ–¥—Å—Ç—Ä–æ–π–∫—É —Ç–µ–º–ø–∞ —Å–¥–µ–ª–∞—Ç—å —á—É—Ç—å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–µ–µ/–º—è–≥—á–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ avg
    # (–ø—Ä–∏–º–µ—Ä –±–µ–∑ —Ä–µ–∑–∫–∏—Ö —Å–∫–∞—á–∫–æ–≤ ‚Äî —Ç–æ–ª—å–∫–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π, –µ—Å–ª–∏ –∑–∞—Ö–æ—á–µ—à—å –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å, —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π)
    # if avg is not None:
    #     if avg > LAT_SLOW_SEC and answer.get("pace") != "—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π":
    #         answer["pace"] = "—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π"
    #     elif avg < LAT_FAST_SEC and answer.get("pace") != "—É—Å–∫–æ—Ä–µ–Ω–Ω—ã–π":
    #         answer["pace"] = "—É—Å–∫–æ—Ä–µ–Ω–Ω—ã–π"

    return answer

# –ø—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—á
Expert.respond = _respond_with_latency

print("‚úÖ Latency tracking integrated: –æ—Ç–≤–µ—Ç —Ç–µ–ø–µ—Ä—å –≤–∫–ª—é—á–∞–µ—Ç latency_sec –∏ latency_avg_sec; –º–µ—Ç—Ä–∏–∫–∏ —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω—ã.")

# ===============================
# ‚è± Fix patch: latency ordering
# + gentle pace auto-adjust
# ===============================
import time
from collections import deque

LAT_FAST_SEC   = 12.0
LAT_SLOW_SEC   = 45.0
LAT_WINDOW_N   = 8
DELTA_ENG_FAST = +0.06
DELTA_ENG_SLOW = -0.06
DELTA_CONF_UP  = +0.05
DELTA_CONF_DN  = -0.07

def _ensure_latency_buffer(context: 'Context'):
    context.progress.setdefault("Expert", {})
    if "latency_buffer" not in context.progress["Expert"]:
        context.progress["Expert"]["latency_buffer"] = deque(maxlen=LAT_WINDOW_N)

# —Å–æ—Ö—Ä–∞–Ω—ë–º —Å—Å—ã–ª–∫—É –Ω–∞ —Ç–µ–∫—É—â–∏–π Expert.respond (—Å —ç–º–ø–∞—Ç–∏–µ–π –∏ —Ç.–ø.)
_old_expert_respond_latency = Expert.respond

def _respond_with_latency_fixed(self, question: str, context: 'Context') -> dict:
    # 1) –∏–∑–º–µ—Ä—è–µ–º —Ä–µ–∞–ª—å–Ω—É—é –∑–∞–¥–µ—Ä–∂–∫—É –ë–ï–ó –∏–∑–º–µ–Ω–µ–Ω–∏—è last_interaction_time
    now = time.time()
    context.progress.setdefault("Expert", {})
    last_ts = context.progress["Expert"].get("last_interaction_time", None)
    latency = None
    if last_ts is not None:
        latency = max(0.0, now - last_ts)

    # 2) –≤—ã–∑—ã–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π respond (–ø—É—Å—Ç—å –æ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç last_ts –∫–∞–∫ –µ—Å—Ç—å)
    answer = _old_expert_respond_latency(self, question, context)

    # 3) –µ—Å–ª–∏ —ç—Ç–æ —Å–±—Ä–æ—Å ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å –∏ –æ–±–Ω–æ–≤–ª—è–µ–º last_interaction_time –Ω–∞ now
    context.progress["Expert"]["last_interaction_time"] = now
    if isinstance(answer, dict) and answer.get("status") == "dialog_cleared":
        return answer

    # 4) –æ–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Å —É—á—ë—Ç–æ–º latency
    _ensure_latency_buffer(context)
    buf: deque = context.progress["Expert"]["latency_buffer"]
    if latency is not None:
        buf.append(latency)

        eng = context.progress["Expert"].get("engagement", 0.5)
        if latency <= LAT_FAST_SEC:
            eng += DELTA_ENG_FAST
        elif latency >= LAT_SLOW_SEC:
            eng += DELTA_ENG_SLOW
        context.progress["Expert"]["engagement"] = min(max(eng, 0.0), 1.0)

        conf = context.progress["Expert"].get("confidence", 0.5)
        if latency >= LAT_SLOW_SEC * 1.5:
            conf += DELTA_CONF_DN/2
        elif latency <= LAT_FAST_SEC/2:
            conf += DELTA_CONF_UP/2
        context.progress["Expert"]["confidence"] = min(max(conf, 0.0), 1.0)

    # 5) –¥–æ–±–∞–≤–∏–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è + –º—è–≥–∫—É—é –∞–≤—Ç–æ–ø–æ–¥—Å—Ç—Ä–æ–π–∫—É —Ç–µ–º–ø–∞ –ø–æ —Å—Ä–µ–¥–Ω–µ–π –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
    avg = (sum(buf) / len(buf)) if buf else None
    answer["latency_sec"] = latency
    answer["latency_avg_sec"] = avg

    if avg is not None:
        # –∞–∫–∫—É—Ä–∞—Ç–Ω–æ, –±–µ–∑ ¬´–¥—ë—Ä–≥–∞–Ω—å—è¬ª: –º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —è–≤–Ω–æ –≤—ã—à–ª–∏ –∑–∞ –ø–æ—Ä–æ–≥–∏
        if avg > LAT_SLOW_SEC and answer.get("pace") != "—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π":
            answer["pace"] = "—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π"
        elif avg < LAT_FAST_SEC and answer.get("pace") != "—É—Å–∫–æ—Ä–µ–Ω–Ω—ã–π":
            answer["pace"] = "—É—Å–∫–æ—Ä–µ–Ω–Ω—ã–π"
        else:
            # –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å (–æ–±—ã—á–Ω—ã–π)
            pass

    return answer

# –ø—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–∫—Å
Expert.respond = _respond_with_latency_fixed

print("‚úÖ Latency fix applied: last_interaction_time –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –ø–æ—Å–ª–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ respond; —Ç–µ–º–ø –ø–æ–¥—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è –ø–æ —Å—Ä–µ–¥–Ω–µ–π –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏.")

# =========================================
# ‚úÖ Unified Expert.respond (no wrappers)
# RAG + memory + levels/tones + empathy + latency
# =========================================
import time, random
from collections import deque

# --- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ (–º–æ–∂–Ω–æ –ø–æ–¥–ø—Ä–∞–≤–∏—Ç—å –ø–æ–¥ —Ä–µ–∂–∏–º live/async)
LAT_FAST_SEC   = 12.0
LAT_SLOW_SEC   = 45.0
LAT_WINDOW_N   = 8
DELTA_ENG_FAST = +0.06
DELTA_ENG_SLOW = -0.06
DELTA_CONF_UP  = +0.05
DELTA_CONF_DN  = -0.07

# –°—Ç—Ä–∞—Ö–æ–≤–∫–∞: —Ç—é–Ω–µ—Ä —ç–º–ø–∞—Ç–∏–∏
try:
    tuner
except NameError:
    try:
        tuner = RelationalTuner(default_tone="warm", position="auto")
    except NameError:
        class _DummyTuner:
            def embellish(self, answer_data, context, user_text=None, tone_override=None, position=None):
                answer_data["answer_empathic"] = answer_data.get("answer", "")
                answer_data["empathy"] = {"situation":"start","tone":"warm","intro":None,"outro":None}
                return answer_data
        tuner = _DummyTuner()

def _ensure_latency_struct(context: 'Context'):
    context.progress.setdefault("Expert", {})
    ex = context.progress["Expert"]
    ex.setdefault("dialog_history", [])
    ex.setdefault("last_answer", None)
    ex.setdefault("engagement", 0.5)
    ex.setdefault("confidence", 0.5)
    ex.setdefault("last_interaction_time", time.time())
    if "latency_buffer" not in ex:
        ex["latency_buffer"] = deque(maxlen=LAT_WINDOW_N)

# === –ü–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞ –º–µ—Ç–æ–¥–∞ respond ===
def _expert_respond_unified(self, question: str, context: 'Context') -> dict:
    print(f"[Expert] –í–æ–ø—Ä–æ—Å: {question}")
    _ensure_latency_struct(context)

    # –°–±—Ä–æ—Å –ø–∞–º—è—Ç–∏
    if question.strip().lower() in {"—Å–±—Ä–æ—Å", "reset", "–æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å"}:
        return reset_dialog(context)

    ex = context.progress["Expert"]

    # 1) Latency: –∏–∑–º–µ—Ä—è–µ–º –ø–æ –ø—Ä–æ—à–ª–æ–º—É —Ç–∞–π–º—Å—Ç–µ–º–ø—É (–Ω–µ –º–µ–Ω—è–µ–º –µ–≥–æ –¥–æ –∫–æ–Ω—Ü–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏)
    now = time.time()
    last_ts = ex.get("last_interaction_time", now)
    latency = max(0.0, now - last_ts) if last_ts else None

    # 2) –û–±–Ω–æ–≤–ª—è–µ–º ¬´—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ¬ª –º–µ—Ç—Ä–∏–∫–∏ (–≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å/—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å) –ø–æ —Ç–µ–∫—Å—Ç—É
    #    (—Ç–≤–æ–∏ —Ñ—É–Ω–∫—Ü–∏–∏/–ª–æ–≥–∏–∫–∞ 5.4)
    # –ü—Ä–æ—Å—Ç–µ–π—à–∞—è –≤–µ—Ä—Å–∏—è: –±—ã—Å—Ç—Ä—ã–π –æ—Ç–≤–µ—Ç ‚Üë –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å, –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Å–¥–≤–∏–≥–∞—é—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
    ql = question.lower()
    if latency is not None:
        if latency <= LAT_FAST_SEC:
            ex["engagement"] = min(1.0, ex.get("engagement",0.5) + DELTA_ENG_FAST)
        elif latency >= LAT_SLOW_SEC:
            ex["engagement"] = max(0.0, ex.get("engagement",0.5) + DELTA_ENG_SLOW)
    if any(w in ql for w in ["–Ω–µ –ø–æ–Ω–∏–º–∞—é","—Å–ª–æ–∂–Ω–æ","—É—Å—Ç–∞–ª","–ø–ª–æ—Ö–æ"]):
        ex["confidence"] = max(0.0, ex.get("confidence",0.5) + DELTA_CONF_DN)
    if any(w in ql for w in ["–ø–æ–ª—É—á–∏–ª–æ—Å—å","—Å–ø–∞—Å–∏–±–æ","–ø–æ–Ω—è—Ç–Ω–æ","–ª–µ–≥–∫–æ"]):
        ex["confidence"] = min(1.0, ex.get("confidence",0.5) + DELTA_CONF_UP)

    # 3) –ù–∞–º–µ—Ä–µ–Ω–∏—è –∏ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è
    intents = detect_intents(question)           # ['why','how','what_if','examples']
    detail  = detect_detail_level(question)      # 'short'|'long' (–∏–ª–∏ —Ç–≤–æ–∏ –≤–∞—Ä–∏–∞–Ω—Ç—ã)

    # 4) –ü–æ–¥–¥–µ—Ä–∂–∫–∞ follow-up
    history = ex["dialog_history"]
    augmented_query, in_reply_to = question, None
    def _is_followup(q: str) -> bool:
        q = q.strip().lower()
        if len(q.split()) <= 4: return True
        if re.match(r"^(–∞|–∏)\b", q): return True
        if re.search(r"\b(–ø–æ–¥—Ä–æ–±–Ω–µ–µ|–ø–æ—è—Å–Ω–∏|—É—Ç–æ—á–Ω–∏|—Ä–∞–∑–≤–µ—Ä–Ω–∏)\b", q): return True
        return False
    if history and _is_followup(question):
        last = history[-1]
        in_reply_to = last.get("question")
        prev_snippet = (last.get("answer") or "")[:200]
        augmented_query = f"{in_reply_to}. {question}. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {prev_snippet}"

    # 5) RAG-–ø–æ–∏—Å–∫
    results = self.kb.search(augmented_query, top_k=2)
    if not results:
        base = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É."
        sources = []
    else:
        combined_text = "\n".join([doc for doc, _, _ in results])
        base = f"–ù–∞ –æ—Å–Ω–æ–≤–µ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –∫—É—Ä—Å–∞:\n{combined_text[:800]}..."
        sources = [name for _, name, _ in results]

    # 6) –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç/–ø–æ—è—Å–Ω–µ–Ω–∏–µ/next_steps
    answer = make_brief(base, 300) if detail == "short" else base
    explanation = make_explanation(base, intents, detail)
    next_steps  = build_next_steps(intents, context)

    # 7) –ü–æ–¥–∞—á–∞ (—Ç–µ–º–ø/–º–∞–Ω–µ—Ä–∞) –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (–º—è–≥–∫–æ)
    conf = ex["confidence"]
    if conf < 0.3:
        pace = "—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π"; tone = "–¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –Ω–∞—Å—Ç–∞–≤–Ω–∏–∫"
    elif conf > 0.7:
        pace = "—É—Å–∫–æ—Ä–µ–Ω–Ω—ã–π";  tone = "–ø–∞—Ä—Ç–Ω—ë—Ä –ø–æ –ø—Ä–æ–µ–∫—Ç—É"
    else:
        pace = "–æ–±—ã—á–Ω—ã–π";     tone = "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å"

    answer_data = {
        "question": question,
        "in_reply_to": in_reply_to,
        "intents": intents,
        "detail": detail,
        "answer": answer,
        "explanation": explanation,
        "sources": sources,
        "next_steps": next_steps,
        "pace": pace,
        "tone": tone,
        "engagement": ex["engagement"],
        "confidence": ex["confidence"]
    }

    # 8) –≠–º–ø–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±–≤—è–∑–∫–∞
    try:
        enriched = tuner.embellish(
            answer_data,
            context,
            user_text=question,
            tone_override=None,
            position=None  # auto
        )
    except Exception:
        enriched = answer_data
        enriched.setdefault("answer_empathic", enriched.get("answer",""))
        enriched.setdefault("empathy", {"situation":"start","tone":"warm","intro":None,"outro":None})

    # 9) Latency buffer + —Å—Ä–µ–¥–Ω—è—è + –º—è–≥–∫–∞—è –∞–≤—Ç–æ–ø–æ–¥—Å—Ç—Ä–æ–π–∫–∞ —Ç–µ–º–ø–∞ –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É
    _ensure_latency_struct(context)
    buf: deque = ex["latency_buffer"]
    if latency is not None:
        buf.append(latency)
    avg = (sum(buf)/len(buf)) if buf else None
    enriched["latency_sec"] = latency
    enriched["latency_avg_sec"] = avg
    if avg is not None:
        if   avg > LAT_SLOW_SEC and enriched.get("pace") != "—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π":
            enriched["pace"] = "—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π"
        elif avg < LAT_FAST_SEC and enriched.get("pace") != "—É—Å–∫–æ—Ä–µ–Ω–Ω—ã–π":
            enriched["pace"] = "—É—Å–∫–æ—Ä–µ–Ω–Ω—ã–π"

    # 10) –û–±–Ω–æ–≤–ª—è–µ–º last_interaction_time —Ç–æ–ª—å–∫–æ –≤ —Å–∞–º–æ–º –∫–æ–Ω—Ü–µ
    ex["last_interaction_time"] = now

    # 11) –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
    history.append(enriched)
    ex["last_answer"] = enriched
    context.progress.setdefault("RelationalTuner", {})
    context.progress["RelationalTuner"]["last"] = enriched.get("empathy")

    return enriched

# –ü–æ–¥–º–µ–Ω—è–µ–º –º–µ—Ç–æ–¥ –∫–ª–∞—Å—Å–∞ –Ω–∞ –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π
Expert.respond = _expert_respond_unified

print("‚úÖ Expert.respond –∑–∞–º–µ–Ω—ë–Ω –Ω–∞ –µ–¥–∏–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç (–±–µ–∑ –æ–±—ë—Ä—Ç–æ–∫): RAG + –ø–∞–º—è—Ç—å + —É—Ä–æ–≤–Ω–∏/—Ç–æ–Ω + —ç–º–ø–∞—Ç–∏—è + latency.")

import random

MOTIVATION_LIBRARY = {
    1: {
        "phrases": [
            "–û—Ç–ª–∏—á–Ω–æ–µ –Ω–∞—á–∞–ª–æ ‚Äî —à–∞–≥ –∑–∞ —à–∞–≥–æ–º!",
            "–¢—ã –Ω–∞ –≤–µ—Ä–Ω–æ–º –ø—É—Ç–∏, –Ω–µ –ø–µ—Ä–µ–∂–∏–≤–∞–π, —á—Ç–æ –ø–æ–∫–∞ —Å–ª–æ–∂–Ω–æ.",
            "–í–∞–∂–Ω–æ, —á—Ç–æ —Ç—ã –ø—Ä–æ–±—É–µ—à—å. –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–∏–¥—ë—Ç.",
            "–°–¥–µ–ª–∞–µ–º —ç—Ç–æ –≤–º–µ—Å—Ç–µ, –Ω–µ —Å–ø–µ—à–∞.",
            "–ü–æ–º–Ω–∏: –∫–∞–∂–¥–∞—è –º–µ–ª–æ—á—å ‚Äî —ç—Ç–æ —á–∞—Å—Ç—å –±–æ–ª—å—à–æ–≥–æ —É—Å–ø–µ—Ö–∞!"
        ],
        "challenges": [
            "–ü–æ–ø—Ä–æ–±—É–π —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –º—ã—Å–ª—å –æ–¥–Ω–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º.",
            "–°–¥–µ–ª–∞–π –º–∞–ª–µ–Ω—å–∫–∏–π —à–∞–≥ ‚Äî –≤—ã–±–µ—Ä–∏ –æ–¥–Ω–æ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ.",
        ]
    },
    2: {
        "phrases": [
            "–Ø —Ä—è–¥–æ–º, –≤–º–µ—Å—Ç–µ —Å–ø—Ä–∞–≤–∏–º—Å—è.",
            "–ù–µ —Å–¥–∞–≤–∞–π—Å—è ‚Äî –∏–Ω–æ–≥–¥–∞ —Ç—Ä—É–¥–Ω–æ—Å—Ç—å –∑–Ω–∞—á–∏—Ç, —á—Ç–æ —Ç—ã —Ä–∞—Å—Ç—ë—à—å.",
            "–û—à–∏–±–∫–∏ ‚Äî —ç—Ç–æ —á–∞—Å—Ç—å –ø—Ä–æ—Ü–µ—Å—Å–∞, –≤—Å—ë –∏–¥—ë—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ.",
            "–ü–æ–¥—É–º–∞–π: —á—Ç–æ –∏–º–µ–Ω–Ω–æ –º–µ—à–∞–µ—Ç? –ú—ã —ç—Ç–æ —Ä–∞–∑–±–µ—Ä—ë–º."
        ],
        "challenges": [
            "–°–¥–µ–ª–∞–π –ø–∞—É–∑—É –∏ –ø–æ–ø—Ä–æ–±—É–π –Ω–∞–π—Ç–∏ –æ–¥–Ω–æ –æ—Ç–ª–∏—á–∏–µ –≤ –ø—Ä–∏–º–µ—Ä–µ.",
            "–°—Ä–∞–≤–Ω–∏ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º —à–∞–≥–æ–º: —á—Ç–æ –ø–æ—Ö–æ–∂–µ, –∞ —á—Ç–æ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è?"
        ]
    },
    3: {
        "phrases": [
            "–û—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ –∏–¥—ë—à—å ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞–π!",
            "–¢—ã —É–∂–µ –º–Ω–æ–≥–æ–µ –ø–æ–Ω—è–ª(–∞).",
            "–•–æ—Ä–æ—à–æ –¥–µ—Ä–∂–∏—à—å —Ç–µ–º–ø, —ç—Ç–æ —Ä–∞–¥—É–µ—Ç.",
            "–û—Ç–ª–∏—á–Ω–æ! –ü–æ–ø—Ä–æ–±—É–π —Å–∞–º(–∞) –æ–±—ä—è—Å–Ω–∏—Ç—å –∫—Ä–∞—Ç–∫–æ."
        ],
        "challenges": [
            "–°—Ä–∞–≤–Ω–∏ —Å–≤–æ—ë —Ä–µ—à–µ–Ω–∏–µ —Å –¥—Ä—É–≥–∏–º –ø–æ–¥—Ö–æ–¥–æ–º.",
            "–ü–æ–ø—Ä–æ–±—É–π –æ–±—ä—è—Å–Ω–∏—Ç—å –∑–∞–¥–∞—á—É –¥—Ä—É–≥—É (–≤ 2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö)."
        ]
    },
    4: {
        "phrases": [
            "–¢—ã –¥–µ–π—Å—Ç–≤—É–µ—à—å —É–≤–µ—Ä–µ–Ω–Ω–æ ‚Äî –∑–¥–æ—Ä–æ–≤–æ!",
            "–°–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å ‚Äî —ç—Ç–æ –∫—Ä—É—Ç–æ.",
            "–°—É–ø–µ—Ä, —Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞–µ—à—å –≤—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å.",
            "–ú–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è —Ç–≤–æ—è –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞."
        ],
        "challenges": [
            "–ü–æ–ø—Ä–æ–±—É–π —Ä–µ—à–∏—Ç—å –∑–∞–¥–∞—á—É –∑–∞ 1 –º–∏–Ω—É—Ç—É.",
            "–ü—Ä–∏–¥—É–º–∞–π —Å–≤–æ–π –ø—Ä–∏–º–µ—Ä –∏ —Å—Ä–∞–≤–Ω–∏ —Å –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏."
        ]
    }
}

# import os
# import glob

# from typing import List
# from pathlib import Path

try:
    from PyPDF2 import PdfReader
except ImportError:
    PdfReader = None

def load_documents(discipline: str) -> List[str]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ .txt, .md, .pdf —Ñ–∞–π–ª—ã –ø–æ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–µ –∏–∑ knowledge_base.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ (–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤).
    """
    folder = os.path.join("knowledge_base", discipline.lower())
    if not os.path.exists(folder):
        print(f"‚ö†Ô∏è –ü–∞–ø–∫–∞ –¥–ª—è –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {folder}")
        return []

    files = glob.glob(os.path.join(folder, "*"))
    documents = []

    for file_path in files:
        ext = Path(file_path).suffix.lower()
        try:
            if ext in [".txt", ".md"]:
                with open(file_path, "r", encoding="utf-8") as f:
                    documents.append(f.read())
            elif ext == ".pdf" and PdfReader:
                reader = PdfReader(file_path)
                text = "\n".join(page.extract_text() for page in reader.pages if page.extract_text())
                documents.append(text)
            else:
                print(f"üî∏ –ü—Ä–æ–ø—É—â–µ–Ω –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–∞–π–ª: {file_path}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file_path}: {e}")

    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ {folder}")
    return documents

# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
kb = KnowledgeBase()
kb.load("–¶–∏—Ñ—Ä–æ–≤–∞—è –∫—É–ª—å—Ç—É—Ä–∞")

# 2. –°–æ–∑–¥–∞–Ω–∏–µ Expert –∏ FSM
expert = Expert(kb)
ctx = Context(
    discipline="–¶–∏—Ñ—Ä–æ–≤–∞—è –∫—É–ª—å—Ç—É—Ä–∞",
    lesson_number=2,
    topic="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Ñ–æ–≥—Ä–∞—Ñ–∏–∫–∏",
    student_level=1
)
fsm = TeachingFSM(ctx, expert=expert)

# 3. –°–∏–º—É–ª—è—Ü–∏—è –¥–∏–∞–ª–æ–≥–∞
fsm.handle_event("init")
fsm.handle_event("student_question", "–ß—Ç–æ —Ç–∞–∫–æ–µ –∏–Ω—Ñ–æ–≥—Ä–∞—Ñ–∏–∫–∞?")
fsm.handle_event("student_question", "–ì–¥–µ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∏–Ω—Ñ–æ–≥—Ä–∞—Ñ–∏–∫–∞?")

# 4. –ü—Ä–æ—Å–º–æ—Ç—Ä –∏—Å—Ç–æ—Ä–∏–∏
from pprint import pprint
pprint(ctx.progress["Expert"]["dialog_history"])

# ============================================
# üé≠ Sprint 8.1 ‚Äî TTS —á–µ—Ä–µ–∑ –µ–¥–∏–Ω—ã–π –∞–¥–∞–ø—Ç–µ—Ä + EventBus
# (–º–æ–∫-—Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è Piper/RHVoice; –∫—ç—à; —ç–º–æ—Ü–∏–∏; tts_done/tts_failed)
# ============================================
from dataclasses import dataclass
from typing import Optional, Dict, Any, List, Tuple
import hashlib, io, wave, math, time, random
import numpy as np

# --- 0) –£—Ç–∏–ª–∏—Ç—ã –∏ —Å–ª–æ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤ Context
def _ensure_tts_slot(context: Context):
    context.progress.setdefault("TTS", {})
    slot = context.progress["TTS"]
    slot.setdefault("cache", {})          # hash -> {"path": "file://...", "sr": 16000, "word_ts": [...], "phonemes": [...]}
    slot.setdefault("dir", "/mnt/data/tts_cache")
    return slot

def _hash_key(text: str, voice: Optional[str], emotion: Optional[str], rate: float) -> str:
    key = f"{text}|{voice or ''}|{emotion or ''}|{rate:.3f}"
    return hashlib.sha1(key.encode("utf-8")).hexdigest()

def _save_wav_16k_mono(samples: np.ndarray, path: str, sr: int = 16000):
    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ int16
    arr = np.clip(samples, -1.0, 1.0)
    i16 = (arr * 32767).astype(np.int16)
    import os
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with wave.open(path, "wb") as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(sr)
        wf.writeframes(i16.tobytes())

# --- 1) –≠–º–æ—Ü–∏–∏ –∏ —Ç–µ–º–ø –∏–∑ Motivator ‚Üí —É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –∫–∞—Ä—Ç–∞
TONE_TO_EMOTION = {
    "warm": "warm",
    "mentor": "warm",
    "partner": "neutral",
    "strict": "calm",
    "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å": "neutral"
}
PACE_TO_RATE = {
    "–∑–∞–º–µ–¥–ª–µ–Ω–Ω—ã–π": 0.9,
    "—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π": 0.95,
    "–æ–±—ã—á–Ω—ã–π": 1.0,
    "—É—Å–∫–æ—Ä–µ–Ω–Ω—ã–π": 1.07
}

def pick_emotion_and_rate(context: Context) -> Tuple[str, float]:
    mot = context.progress.get("Motivator", {}).get("last", {})
    style = mot.get("style", {}) if isinstance(mot, dict) else {}
    tone = style.get("tone", "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å")
    pace = style.get("pace", "–æ–±—ã—á–Ω—ã–π")
    emotion = TONE_TO_EMOTION.get(tone, "neutral")
    rate = PACE_TO_RATE.get(pace, 1.0)
    return emotion, rate

# --- 2) –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å TTS
class BaseTTSAdapter:
    sr: int = 16000

    def synthesize(self, text: str, voice: Optional[str] = None,
                   emotion: Optional[str] = None, rate: float = 1.0) -> Dict[str, Any]:
        """
        –î–û–õ–ñ–ï–ù –≤–µ—Ä–Ω—É—Ç—å:
        {
          "wav": bytes,
          "sr": 16000,
          "word_ts": [{"t0": float, "t1": float, "word": str}, ...],
          "phonemes": ["p","a","t",...]
        }
        """
        raise NotImplementedError

# --- 3) –ú–æ–∫-–∞–¥–∞–ø—Ç–µ—Ä Piper (–≥–µ–Ω–µ—Ä–∏—Ç —Å–∏–Ω—É—Å/–∞–º-–ø–∞—É–∑—ã; –¥–∞—ë—Ç word_ts/phonemes)
class PiperAdapter(BaseTTSAdapter):
    def synthesize(self, text: str, voice=None, emotion=None, rate: float = 1.0) -> Dict[str, Any]:
        sr = self.sr
        # –ø—Ä–æ—Å—Ç–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 70 –º—Å –Ω–∞ —Å–ª–æ–≤–æ * –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç / rate
        words = [w for w in text.strip().split() if w]
        base_per_word = 0.07
        dur = max(0.5, len(words) * base_per_word / max(0.5, rate))
        t = np.linspace(0, dur, int(sr * dur), endpoint=False)
        # —á–∞—Å—Ç–æ—Ç–∞ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —ç–º–æ—Ü–∏–∏
        f0 = {"warm": 180, "neutral": 160, "calm": 140, "excited": 220}.get(emotion or "neutral", 160)
        x = 0.15 * np.sin(2 * math.pi * f0 * t)
        # ¬´–ø–∞—É–∑—ã¬ª –ø–æ—Å–ª–µ —Ç–æ—á–µ–∫/–∑–∞–ø—è—Ç—ã—Ö: —Å–Ω–∏–∂–µ–Ω–Ω–∞—è –∞–º–ø–ª–∏—Ç—É–¥–∞
        if "," in text or "." in text:
            x[int(len(x)*0.6):int(len(x)*0.65)] *= 0.2

        # —Ç–∞–π–º–∏–Ω–≥–∏ —Å–ª–æ–≤ ‚Äî —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ
        word_ts = []
        if words:
            word_len = dur / len(words)
            for i, w in enumerate(words):
                t0 = i * word_len
                t1 = (i+1) * word_len
                word_ts.append({"t0": round(t0, 3), "t1": round(t1, 3), "word": w})

        # ¬´—Ñ–æ–Ω–µ–º—ã¬ª ‚Äî –≥—Ä—É–±–∞—è —Å—Ö–µ–º–∞ –ø–æ –±—É–∫–≤–∞–º (–¥–ª—è —Ç–µ—Å—Ç–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞)
        raw = "".join([c for c in text.lower() if c.isalpha()])
        phonemes = list(raw[:64])  # –æ–≥—Ä–∞–Ω–∏—á–∏–º

        # –≤ –±–∞–π—Ç—ã WAV
        bio = io.BytesIO()
        with wave.open(bio, "wb") as wf:
            wf.setnchannels(1); wf.setsampwidth(2); wf.setframerate(sr)
            wf.writeframes((x * 32767).astype(np.int16).tobytes())
        return {"wav": bio.getvalue(), "sr": sr, "word_ts": word_ts, "phonemes": phonemes}

# --- 4) –ú–æ–∫-–∞–¥–∞–ø—Ç–µ—Ä RHVoice (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ, —á—É—Ç—å –¥—Ä—É–≥–∞—è –æ—Å–Ω–æ–≤–∞)
class RHVoiceAdapter(BaseTTSAdapter):
    def synthesize(self, text: str, voice=None, emotion=None, rate: float = 1.0) -> Dict[str, Any]:
        sr = self.sr
        words = [w for w in text.strip().split() if w]
        dur = max(0.6, len(words) * 0.08 / max(0.5, rate))
        t = np.linspace(0, dur, int(sr * dur), endpoint=False)
        f0 = {"warm": 170, "neutral": 150, "calm": 130, "excited": 210}.get(emotion or "neutral", 150)
        # —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫ + –ª—ë–≥–∫–∏–π —à—É–º
        tri = 2 * np.abs((t * f0) % 1 - 0.5) - 0.5
        x = 0.12 * tri + 0.02*np.random.randn(len(t))
        # —Ç–∞–π–º–∏–Ω–≥–∏ —Å–ª–æ–≤
        word_ts = []
        if words:
            word_len = dur / len(words)
            for i, w in enumerate(words):
                t0 = i * word_len
                t1 = (i+1) * word_len
                word_ts.append({"t0": round(t0, 3), "t1": round(t1, 3), "word": w})
        phonemes = list("".join([c for c in text.lower() if c.isalpha()])[:64])
        # –≤ –±–∞–π—Ç—ã WAV
        bio = io.BytesIO()
        with wave.open(bio, "wb") as wf:
            wf.setnchannels(1); wf.setsampwidth(2); wf.setframerate(sr)
            wf.writeframes((np.clip(x, -1, 1) * 32767).astype(np.int16).tobytes())
        return {"wav": bio.getvalue(), "sr": sr, "word_ts": word_ts, "phonemes": phonemes}

# --- 5) –í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π —Ñ–∞—Å–∞–¥ TTS —Å –∫—ç—à–µ–º
class TTSService:
    def __init__(self, adapter: BaseTTSAdapter, default_voice: Optional[str]=None):
        self.adapter = adapter
        self.default_voice = default_voice

    def synthesize(self, context: Context, text: str,
                   voice: Optional[str]=None, emotion: Optional[str]=None, rate: float=1.0) -> Dict[str, Any]:
        slot = _ensure_tts_slot(context)
        key = _hash_key(text, voice or self.default_voice, emotion, rate)

        # –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–∑—ã ‚Äî –∫—ç—à–∏—Ä—É–µ–º (<= 120 —Å–∏–º–≤–æ–ª–æ–≤)
        if len(text) <= 120 and key in slot["cache"]:
            return {"cache_hit": True, **slot["cache"][key]}

        data = self.adapter.synthesize(text=text, voice=voice or self.default_voice, emotion=emotion, rate=rate)

        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª –¥–ª—è Unity (file://)
        path = f'{slot["dir"]}/{key}.wav'
        _save_wav_16k_mono(
            samples=(np.frombuffer(data["wav"], dtype=np.int16).astype(np.float32)/32767.0
                     if isinstance(data["wav"], (bytes, bytearray)) else data["wav"]),
            path=path, sr=data["sr"]
        )
        rec = {"path": f"file://{path}", "sr": data["sr"], "word_ts": data.get("word_ts", []), "phonemes": data.get("phonemes", [])}
        if len(text) <= 120:
            slot["cache"][key] = rec
        return rec

# --- 6) ¬´–°—Ü–µ–Ω–∞—Ä–∏—Å—Ç¬ª —Ä–µ—á–∏ (–º–∏–∫—Ä–æ-8.3): —Å–æ–±–∏—Ä–∞–µ–º intro/core/outro
def build_say_script_from_answer(answer: Dict[str, Any], context: Context) -> Dict[str, Any]:
    # intro/outro ‚Äî –ª—ë–≥–∫–∏–µ, –µ—Å–ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ –µ—Å—Ç—å —ç–º–ø–∞—Ç–∏—è, –º–æ–∂–Ω–æ –ø–æ–¥—Å—Ç–∞–≤–∏—Ç—å —Ç—É–¥–∞;
    # –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –±–µ—Ä—ë–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–∑—ã –∏–∑ –º–æ—Ç–∏–≤–∞—Ü–∏–∏
    mot = context.progress.get("Motivator", {}).get("last", {})
    mot_phrase = (mot.get("motivation") or {}).get("phrase")
    intro = None
    if mot_phrase:
        intro = mot_phrase if len(mot_phrase.split()) <= 10 else None

    core = answer.get("answer", "") or ""
    outro = None
    challenge = (mot.get("motivation") or {}).get("challenge")
    if challenge and len(challenge.split()) <= 10:
        outro = challenge

    lines = []
    if intro: lines.append({"role":"intro","text":intro})
    if core:  lines.append({"role":"core","text":core})
    if outro: lines.append({"role":"outro","text":outro})

    # –ø–æ–¥—Å–∫–∞–∑–∫–∏ —ç–º–æ—Ü–∏–π/–∂–µ—Å—Ç–æ–≤ (–º–∏–Ω–∏–º—É–º)
    emotion, _ = pick_emotion_and_rate(context)
    return {"lines": lines, "emotion_hint": emotion, "gesture_hints": []}

# --- 7) –ü–æ–¥–ø–∏—Å—á–∏–∫ EventBus: expert_answer -> build_say_script -> TTS -> publish tts_done/tts_failed
def make_expert_answer_handler_tts(tts: TTSService, bus: EventBus):
    def _handler(ev: Event):
        try:
            ans = ev.payload.get("answer", {}) or {}
            text_full = ans.get("answer") or ""
            if not isinstance(text_full, str) or not text_full.strip():
                # –Ω–∏—á–µ–≥–æ —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å
                return

            # —Å—Ü–µ–Ω–∞—Ä–∏—Å—Ç: –∏–Ω—Ç—Ä–æ/—è–¥—Ä–æ/–∞—É—Ç—Ä–æ ‚Üí —Å–∫–ª–µ–∏–≤–∞–µ–º –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –¥–ª—è TTS
            say = build_say_script_from_answer(ans, bus.context)
            text_parts = [seg["text"] for seg in say.get("lines", []) if seg.get("text")]
            text_tts = (" ".join(text_parts)).strip() or text_full.strip()

            # —ç–º–æ—Ü–∏—è/—Å–∫–æ—Ä–æ—Å—Ç—å –∏–∑ Motivator
            emotion, rate = pick_emotion_and_rate(bus.context)

            # —Å–∏–Ω—Ç–µ–∑
            out = tts.synthesize(bus.context, text=text_tts, emotion=emotion, rate=rate)

            # –ø—É–±–ª–∏–∫—É–µ–º tts_done
            bus.publish(Event(
                type="tts_done",
                source="tts",
                payload={
                    "text": text_tts,
                    "audio": out["path"],         # file://...
                    "sr": out["sr"],
                    "word_ts": out.get("word_ts", []),
                    "phonemes": out.get("phonemes", []),
                    "emotion": emotion
                }
            ))
        except Exception as e:
            bus.publish(Event(
                type="tts_failed",
                source="tts",
                payload={"reason": str(e), "fallback_text": ev.payload.get("answer", {}).get("answer", "")}
            ))
    return _handler

# --- 8) –•–µ–ª–ø–µ—Ä: —Å–æ–∑–¥–∞—Ç—å —Å–µ—Ä–≤–∏—Å –∏ –ø—Ä–∏–∫—Ä—É—Ç–∏—Ç—å –∫ bus
def attach_tts_to_bus(bus: EventBus, engine: str = "piper", default_voice: Optional[str]=None) -> TTSService:
    adapter = PiperAdapter() if engine.lower()=="piper" else RHVoiceAdapter()
    tts = TTSService(adapter=adapter, default_voice=default_voice)
    bus.subscribe("expert_answer", make_expert_answer_handler_tts(tts, bus))

    # –±–∞–∑–æ–≤–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    def _logger(ev: Event):
        print(f"ü™µ [LOG] {ev.type} <- {ev.source} :: keys={list(ev.payload.keys())}")
    bus.subscribe("tts_done", _logger)
    bus.subscribe("tts_failed", _logger)
    return tts

# ============================================
# üîÅ Sprint 7.3 ‚Äî –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Ü–∏–∫–ª–∞ –∑–∞–Ω—è—Ç–∏—è
# ============================================
from typing import Dict, Any, Optional
import copy
import time

# --- 1) –°–Ω–∞–ø—à–æ—Ç/—Ä–µ—Å—Ç–∞–≤—Ä–∞—Ü–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (–±–µ—Ä–µ–∂–Ω–æ) ---

def snapshot_progress(context: Context) -> Dict[str, Any]:
    """
    –î–µ–ª–∞–µ–º –Ω–µ–≥–ª—É–±–æ–∫–∏–π —Å–Ω–∏–º–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–¥—É–ª–µ–π; 
    Organizer + Motivator —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é; Expert ‚Äî —Ç–æ–ª—å–∫–æ –º–µ—Ç—Ä–∏–∫–∏/–ø–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç–≤–µ—Ç.
    """
    p = context.progress
    snap = {
        "Motivator": copy.deepcopy(p.get("Motivator", {})),
        "Organizer": copy.deepcopy(p.get("Organizer", {})),
        "Expert_meta": {
            "engagement": (p.get("Expert", {}) or {}).get("engagement"),
            "confidence": (p.get("Expert", {}) or {}).get("confidence"),
            "latency_avg_sec": (p.get("Expert", {}) or {}).get("latency_avg_sec"),
            "last_answer": (p.get("Expert", {}) or {}).get("last_answer"),
        },
        "Cartographer": copy.deepcopy(p.get("Cartographer", {})),
        "EventBus_log_tail": copy.deepcopy((p.get("EventBus", {}) or {}).get("log", [])[-20:])
    }
    return snap

def restore_progress(context: Context, snap: Dict[str, Any], *, full: bool):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –∫—É—Å–∫–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞.
    full=True: –æ—á–∏—â–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é Expert (–¥–∏–∞–ª–æ–≥), –æ—Å—Ç–∞–ª—å–Ω–æ–µ –±–µ—Ä–µ–∂—ë–º.
    """
    p = context.progress
    p.setdefault("Motivator", {}).update(snap.get("Motivator", {}))
    p.setdefault("Organizer", {}).update(snap.get("Organizer", {}))
    p.setdefault("Cartographer", {}).update(snap.get("Cartographer", {}))

    p.setdefault("Expert", {})
    if full:
        # –ü–æ–ª–Ω—ã–π —Ä–µ—Å—Ç–∞—Ä—Ç: —á–∏—Å—Ç–∏–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞, –Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ–ª–µ–∑–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        p["Expert"]["dialog_history"] = []
        p["Expert"]["last_answer"] = None
    # –í–µ—Ä–Ω—ë–º –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —ç–∫—Å–ø–µ—Ä—Ç–∞
    for k, v in (snap.get("Expert_meta") or {}).items():
        if v is not None:
            p["Expert"][k] = v

# --- 2) –•–µ–ª–ø–µ—Ä—ã —Ä–µ—Å—Ç–∞—Ä—Ç–∞ —ç—Ç–∞–ø–∞/–≤—Å–µ–≥–æ –∑–∞–Ω—è—Ç–∏—è ---

def restart_current_stage(conductor: 'Conductor', bus: EventBus, *, reason: str = ""):
    """
    –ú—è–≥–∫–∏–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Ç–µ–∫—É—â–µ–≥–æ —ç—Ç–∞–ø–∞: 
    - –ø–æ–≤—Ç–æ—Ä–Ω–æ –æ–±—ä—è–≤–ª—è–µ–º stage_changed –Ω–∞ —Ç—É –∂–µ —Å—Ç–∞–¥–∏—é
    - —Ç—Ä–∏–≥–≥–µ—Ä–∏–º –±–∞–∑–æ–≤—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –¥–ª—è —ç—Ç–∞–ø–∞ (goals/tasks/work/reflection/wrapup)
    """
    stage = conductor.stage
    bus.publish(Event(type="stage_changed", source="conductor", payload={"stage": stage, "reason": reason or "restart_stage"}))

    # –õ–æ–∫–∞–ª—å–Ω—ã–µ ¬´–ø–µ—Ä–µ-–≤—Ö–æ–¥—ã¬ª –≤ —ç—Ç–∞–ø (—Ç–æ, —á—Ç–æ –≤—ã –¥–µ–ª–∞–ª–∏ –≤ 7.2)
    if stage == "goals":
        # –ø–æ–¥—Å–∫–∞–∑–∫–∞ Cartographer/Organizer, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if 'Organizer' in globals():
            org = Organizer()
            bus.publish(Event(type="expert_answer", source="system", payload={"question": "[auto] —Ü–µ–ª–∏", "answer": {"note": "refresh goals"}}))
            bus.publish(Event(type="organizer_update", source="organizer", payload={"organizer": org.process(bus.context)}))

    elif stage == "tasks":
        if 'Organizer' in globals():
            org = Organizer()
            bus.publish(Event(type="organizer_update", source="organizer", payload={"organizer": org.process(bus.context)}))

    elif stage == "work":
        # –º—è–≥–∫–∏–π –ø–∏–Ω–≥ –º–æ—Ç–∏–≤–∞—Ü–∏–∏ –Ω–∞ ¬´—Ä–∞–±–æ—Ç—É¬ª
        bus.publish(Event(type="motivation_update", source="system", payload={"last": (bus.context.progress.get("Motivator") or {}).get("last", {})}))

    elif stage == "reflection":
        # –º—è–≥–∫–∏–π —Ä–µ—Ñ–ª–µ–∫—Å–∏–≤–Ω—ã–π –≤–æ–ø—Ä–æ—Å
        bus.publish(Event(type="student_question", source="system", payload={"text": "–î–∞–≤–∞–π –∫–æ—Ä–æ—Ç–∫–æ –ø–æ–¥—É–º–∞–µ–º: —á—Ç–æ —Å–µ–π—á–∞—Å –º–µ—à–∞–µ—Ç –¥–≤–∏–≥–∞—Ç—å—Å—è –¥–∞–ª—å—à–µ?"}))

    elif stage == "wrapup":
        # —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–≤–µ–∂—É—é –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É (–∫–∞–∫ –≤ 7.2)
        summary = {
            "topic": bus.context.topic,
            "answers_count": len((bus.context.progress.get("Expert", {}) or {}).get("dialog_history", [])),
            "work_turns": 0,  # –º–æ–∂–Ω–æ –¥–æ—Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –∏–∑ Conductor
            "tasks_available": bool((bus.context.progress.get("Organizer", {}) or {}).get("tasks")),
            "motivation_level": (bus.context.progress.get("Motivator", {}) or {}).get("level", 1),
            "style": (bus.context.progress.get("Motivator", {}) or {}).get("last", {}).get("style", {})
        }
        bus.publish(Event(type="lesson_finished", source="conductor", payload={"summary": summary}))

def restart_full(conductor: 'Conductor', bus: EventBus, *, reason: str = ""):
    """
    –ü–æ–ª–Ω—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –∑–∞–Ω—è—Ç–∏—è:
    - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å (Motivator/Organizer/–º–µ—Ç—Ä–∏–∫–∏)
    - —á–∏—Å—Ç–∏–º Expert –¥–∏–∞–ª–æ–≥ –∏ —Å—Ç–∞–≤–∏–º —Å—Ü–µ–Ω—É 'start'
    - —Å–Ω–æ–≤–∞ –ø—Ä–æ–≤–æ–¥–∏–º —Ü–µ–ª–∏/–∑–∞–¥–∞–Ω–∏—è
    """
    ctx = bus.context
    snap = snapshot_progress(ctx)

    # –°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤–µ–¥—É—â–µ–≥–æ —Ü–∏–∫–ª–∞
    conductor.stage = "start"
    conductor.answers_count = 0
    conductor.work_turns = 0

    restore_progress(ctx, snap, full=True)

    # –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞ —ç—Ç–∞–ø–æ–≤, –∫–∞–∫ –≤ 7.2
    bus.publish(Event(type="stage_changed", source="conductor", payload={"stage": "goals", "reason": reason or "restart_full"}))
    if 'Organizer' in globals():
        org = Organizer()
        bus.publish(Event(type="organizer_update", source="organizer", payload={"organizer": org.process(ctx)}))
    bus.publish(Event(type="stage_changed", source="conductor", payload={"stage": "tasks"}))

# --- 3) –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–±—ã—Ç–∏—è 'restart' –¥–ª—è —à–∏–Ω—ã ---

def make_restart_handler(conductor: 'Conductor', bus: EventBus):
    def _handler(ev: Event):
        mode = (ev.payload or {}).get("mode", "stage")
        reason = (ev.payload or {}).get("reason", "")
        cur = conductor._stage()  # <-- –≤–º–µ—Å—Ç–æ conductor.stage

        if mode == "full":
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ—Ç–∏–≤–∞—Ü–∏—é/–ø—Ä–æ–≥—Ä–µ—Å—Å, –Ω–æ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫ work_turns
            slot = bus.context.progress.setdefault("Conductor", {})
            slot["work_turns"] = 0
            slot["summary"] = {}
            # –°—Ç–∞–¥–∏—è "start" –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ü–∏–∫–ª –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
            conductor._set_stage("start")  # <-- –≤–º–µ—Å—Ç–æ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏—è .stage
            bus.publish(Event(type="init", source="conductor", payload={"restart": "full", "reason": reason}))
            return {"status": "restarted_full", "stage": conductor._stage()}

        # –ß–∞—Å—Ç–∏—á–Ω—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Ç–µ–∫—É—â–µ–π —Å—Ç–∞–¥–∏–∏
        # –ü—Ä–æ—Å—Ç–æ –ø–æ–≤—Ç–æ—Ä—è–µ–º –≤—Ö–æ–¥–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è —Å—Ç–∞–¥–∏–∏
        if cur in {"start", "goals"}:
            goals = _get_or_make_goals(bus.context)
            conductor._set_stage("goals")
            bus.publish(Event(type="goals_ready", source="conductor", payload={"goals": goals, "restart": "stage"}))
        elif cur == "tasks":
            conductor._set_stage("tasks")
            bus.publish(Event(
                type="tasks_ready", source="conductor",
                payload={"has_tasks": conductor._has_tasks(), "restart": "stage"}
            ))
        elif cur == "work":
            # –ù–∞ —Ä–∞–±–æ—Ç–µ –ø—Ä–æ—Å—Ç–æ –º—è–≥–∫–æ ¬´–ø–æ–¥—Ç–æ–ª–∫–Ω—ë–º¬ª –º–æ—Ç–∏–≤–∞—Ü–∏—é/–æ—Ä–≥–∞–Ω–∞–π–∑–µ—Ä –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
            conductor._set_stage("work")
            # –ù–∏—á–µ–≥–æ –Ω–µ –ø—É–±–ª–∏–∫—É–µ–º ‚Äî —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å —Å—Ç—É–¥–µ–Ω—Ç–∞ –ø—Ä–æ–π–¥—ë—Ç –æ–±—ã—á–Ω—ã–º –º–∞—Ä—à—Ä—É—Ç–æ–º
        elif cur == "reflection":
            conductor._set_stage("reflection")
            bus.publish(Event(type="ask_reflection", source="conductor",
                              payload={"reason": "restart_stage"}))
        elif cur == "wrapup":
            # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ ¬´–∏—Ç–æ–≥–∞¬ª ‚Äî –ø–µ—Ä–µ—Å–æ–±–µ—Ä—ë–º summary
            conductor._set_stage("wrapup")
            conductor._finish()
        else:
            # finished –∏–ª–∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è ‚Äî –Ω–∞—á–∏–Ω–∞–µ–º —Å–Ω–∞—á–∞–ª–∞
            conductor._set_stage("start")
            bus.publish(Event(type="init", source="conductor", payload={"restart": "from_finished"}))

        return {"status": "restarted_stage", "stage": conductor._stage(), "previous": cur}
    return _handler

# --- 4) –ü–æ–¥–ø–∏—Å–∫–∞ EventBus –Ω–∞ 'restart' (—Ä–∞–∑–æ–≤–æ, –ø–æ—Å–ª–µ build_event_bus –∏ —Å–æ–∑–¥–∞–Ω–∏—è Conductor) ---
# –ü—Ä–∏–º–µ—Ä (—Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –∑–¥–µ—Å—å –∂–µ):
bus.subscribe("restart", make_restart_handler(conductor, bus))

# --- 5) –ú–∏–Ω–∏‚Äë–ø—Ä–æ–≤–µ—Ä–∫–∞ 7.3 (–æ–∂–∏–¥–∞–µ—Ç—Å—è, —á—Ç–æ –µ—Å—Ç—å bus, conductor, expert, ctx) ---

def test_restart_via_bus(bus: EventBus, conductor: 'Conductor'):
    print("‚ñ∂Ô∏è –°—Ç–∞—Ä—Ç —Ç–µ—Å—Ç–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞")
    print("–¢–µ–∫—É—â–∞—è —Å—Ç–∞–¥–∏—è:", conductor._stage())   # <- –±—ã–ª–æ conductor.stage

    print("\n‚Äî –ß–∞—Å—Ç–∏—á–Ω—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Ç–µ–∫—É—â–µ–≥–æ —ç—Ç–∞–ø–∞")
    bus.publish(Event(type="restart", source="tester",
                      payload={"mode": "stage", "reason": "retry_current"}))
    time.sleep(0.05)

    bus.publish(Event(type="student_question", source="student",
                      payload={"text": "–ú–æ–∂–Ω–æ –µ—â—ë —Ä–∞–∑ –ø—Ä–æ –≤—ã–±–æ—Ä –¥–∏–∞–≥—Ä–∞–º–º—ã?"}))
    time.sleep(0.05)

    print("\n‚Äî –ü–æ–ª–Ω—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ (—Å –Ω–∞—á–∞–ª–∞)")
    bus.publish(Event(type="restart", source="tester",
                      payload={"mode": "full", "reason": "not_understood"}))
    time.sleep(0.05)

    bus.publish(Event(type="student_question", source="student",
                      payload={"text": "–û–∫, –ø–æ–≤—Ç–æ—Ä–∏–º —Ü–µ–ª–∏ –∑–∞–Ω—è—Ç–∏—è –∫—Ä–∞—Ç–∫–æ?"}))
    time.sleep(0.05)

    from pprint import pprint
    print("\nüìú –•–≤–æ—Å—Ç EventBus –ª–æ–≥–∞:")
    pprint(bus.context.progress["EventBus"]["log"][-8:])
    print("–¢–µ–∫—É—â–∞—è —Å—Ç–∞–¥–∏—è:", conductor._stage())   # <- –±—ã–ª–æ conductor.stage

import json, csv, os, time
from datetime import datetime

def _ts_human(ts: float) -> str:
    try:
        return datetime.fromtimestamp(ts).strftime("%Y-%m-%d %H:%M:%S")
    except Exception:
        return ""

def export_eventbus_logs(ctx,
                         json_path: str = None,
                         csv_path: str = None,
                         extra_meta: dict = None):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç EventBus –ª–æ–≥ + —Å–≤–æ–¥–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ JSON/CSV."""
    eb = (ctx.progress.get("EventBus") or {})
    log = eb.get("log", [])
    session_id = eb.get("id", "unknown-session")

    # --- –±–∞–∑–æ–≤—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    meta = {
        "session_id": session_id,
        "saved_at_ts": time.time(),
        "saved_at": _ts_human(time.time()),
        "discipline": getattr(ctx, "discipline", None),
        "topic": getattr(ctx, "topic", None),
        "lesson_number": getattr(ctx, "lesson_number", None),
    }

    # --- —Å—Ä–µ–∑ –ø–æ –º–æ–¥—É–ª—è–º
    expert = ctx.progress.get("Expert", {})
    motiv  = ctx.progress.get("Motivator", {})
    org    = ctx.progress.get("Organizer", {})
    cond   = ctx.progress.get("Conductor", {})

    last_answer = (expert.get("dialog_history") or [])[-1] if expert.get("dialog_history") else None

    meta["modules"] = {
        "Expert": {
            "history_len": len(expert.get("dialog_history", [])),
            "last_question": (last_answer or {}).get("question"),
            "last_intents": (last_answer or {}).get("intents"),
            "last_detail":  (last_answer or {}).get("detail"),
        },
        "Motivator": {
            "level": motiv.get("level"),
            "last":  motiv.get("last"),
            "drop_count": ctx.progress.get("Motivator", {}).get("drop_count", 0),
        },
        "Organizer": {
            "tasks_count": len((org.get("tasks") or [])) if isinstance(org.get("tasks"), list) else None,
        },
        "Conductor": {
            "stage": cond.get("stage"),
            "work_turns": cond.get("work_turns"),
            "summary": cond.get("summary"),
        }
    }

    if extra_meta:
        meta.update({"extra": extra_meta})

    # --- JSON (–ø–æ–ª–Ω—ã–π)
    if json_path is None:
        json_path = f"./logs_{session_id}_{int(time.time())}.json"

    os.makedirs(os.path.dirname(json_path) or ".", exist_ok=True)
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump({"meta": meta, "eventbus_log": log}, f, ensure_ascii=False, indent=2)

    # --- CSV (–ø–ª–æ—Å–∫–∏–π —Ö–≤–æ—Å—Ç —Å–æ–±—ã—Ç–∏–π)
    if csv_path is None:
        csv_path = f"./logs_{session_id}_{int(time.time())}.csv"

    with open(csv_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=["ts","ts_human","type","source","payload_keys"])
        writer.writeheader()
        for rec in log:
            writer.writerow({
                "ts": rec.get("ts"),
                "ts_human": _ts_human(rec.get("ts")),
                "type": rec.get("type"),
                "source": rec.get("source"),
                "payload_keys": ",".join(rec.get("payload_keys", [])),
            })

    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ:\n- JSON: {json_path}\n- CSV:  {csv_path}")
    return {"json": json_path, "csv": csv_path, "meta": meta}

# –ü—Ä–∏–º–µ—Ä –≤—ã–∑–æ–≤–∞:
# export_eventbus_logs(ctx)

# ============================================
# üß™ Sprint 7.4 ‚Äî –°—Ü–µ–Ω–∞—Ä–Ω—ã–µ –ø—Ä–æ–≥–æ–Ω—ã –∏ –æ—Ç–ª–∞–¥–∫–∞
# –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã ctx, expert, motivator, (organizer), bus, conductor
# ============================================
from pprint import pprint
import time, random

def _tail_log(n=10):
    return ctx.progress.get("EventBus", {}).get("log", [])[-n:]

def _stage():
    return ctx.progress.get("Conductor", {}).get("stage")

def _mot():
    return ctx.progress.get("Motivator", {}).get("last", {})

def _org_has_tasks():
    org = ctx.progress.get("Organizer", {})
    return bool(org.get("tasks"))

def _answers_count():
    return len(ctx.progress.get("Expert", {}).get("dialog_history", []))

def _reset_for_scenario():
    # –º—è–≥–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã—Ö —á–∞—Å—Ç–µ–π, –±–µ–∑ —Å–Ω–æ—Å–∞ –∏–Ω–¥–µ–∫—Å–∞/KB
    ctx.progress["EventBus"]["log"] = []
    ctx.progress["Conductor"]["work_turns"] = 0
    ctx.progress["Conductor"]["summary"] = {}
    ctx.progress["Conductor"]["stage"] = "start"
    ctx.progress.setdefault("Reflection", {})["asked"] = []
    # –Ω–µ —Ç—Ä–æ–≥–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é Expert/Motivator ‚Äî —Ö–æ—Ç–∏–º —Å–º–æ—Ç—Ä–µ—Ç—å –∫—É–º—É–ª—è—Ç–∏–≤–Ω–æ
    bus.publish(Event(type="init", source="tester", payload={}))

def _print_header(title):
    print("\n" + "="*6, title, "="*6)

# ---------- –°—Ü–µ–Ω–∞—Ä–∏–π 1: –í—Å—ë –∏–¥—ë—Ç –≥–ª–∞–¥–∫–æ ----------
def scenario_smooth():
    _print_header("–°—Ü–µ–Ω–∞—Ä–∏–π 1: –≤—Å—ë –∏–¥—ë—Ç –≥–ª–∞–¥–∫–æ")
    _reset_for_scenario()

    # goals -> tasks -> work –¥–≤–∏–∂–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ Conductor.on_init
    # –†–∞–±–æ—Ç–∞: 2 —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞
    bus.publish(Event(type="student_question", source="student",
                      payload={"text": "–° —á–µ–≥–æ –Ω–∞—á–∞—Ç—å –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–Ω—Ñ–æ–≥—Ä–∞—Ñ–∏–∫–∏?"}))
    time.sleep(0.05)
    bus.publish(Event(type="student_question", source="student",
                      payload={"text": "–ö–∞–∫ –≤—ã–±—Ä–∞—Ç—å –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Ç–∏–ø –¥–∏–∞–≥—Ä–∞–º–º—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è?"}))
    time.sleep(0.05)

    # –û—Ç–≤–µ—Ç —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏
    bus.publish(Event(type="student_reflection", source="student",
                      payload={"text": "–ù–µ–º–Ω–æ–≥–æ –≤–æ–ª–Ω–æ–≤–∞–ª—Å—è, –Ω–æ —Å—Ç–∞–ª–æ –ø–æ–Ω—è—Ç–Ω–µ–µ."}))
    time.sleep(0.05)

    print("–°—Ç–∞–¥–∏—è:", _stage())
    print("–û—Ç–≤–µ—Ç–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–∞:", _answers_count())
    print("–ï—Å—Ç—å –∑–∞–¥–∞–Ω–∏—è –æ—Ç Organizer:", _org_has_tasks())
    print("Motivator:", {k:_mot().get(k) for k in ["level","level_name","style"]})
    print("–•–≤–æ—Å—Ç –ª–æ–≥–∞:")
    pprint(_tail_log(6))

# ---------- –°—Ü–µ–Ω–∞—Ä–∏–π 2: –°—Ç—É–¥–µ–Ω—Ç —á–∞—Å—Ç–æ –æ—à–∏–±–∞–µ—Ç—Å—è ----------
def scenario_mistakes():
    _print_header("–°—Ü–µ–Ω–∞—Ä–∏–π 2: —á–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏/—Å–æ–º–Ω–µ–Ω–∏—è")
    _reset_for_scenario()

    bad_prompts = [
        "–Ø –æ—à–∏–±—Å—è —Å –ø–æ–¥–ø–∏—Å—è–º–∏‚Ä¶",
        "–ù–µ –ø–æ–Ω–∏–º–∞—é, –ø–æ—á–µ–º—É –Ω–µ–≤–µ—Ä–Ω–æ –ø–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä—É—é—Ç—Å—è –º–µ—Ç–∫–∏",
        "–ù–∞–≤–µ—Ä–Ω–æ–µ, –æ–ø—è—Ç—å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–¥–µ–ª–∞–ª",
        "–•–º‚Ä¶"
    ]
    for q in bad_prompts:
        bus.publish(Event(type="student_question", source="student", payload={"text": q}))
        time.sleep(0.05)

    mot = _mot()
    print("–°—Ç–∞–¥–∏—è:", _stage())
    print("–û—Ç–≤–µ—Ç–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–∞:", _answers_count())
    print("Motivator level:", mot.get("level"), mot.get("level_name"))
    print("–°–∏–≥–Ω–∞–ª—ã:", mot.get("signals"))
    print("–°—á—ë—Ç—á–∏–∫ –ø–∞–¥–µ–Ω–∏–π (drop_count):", mot.get("drop_count"))
    print("–•–≤–æ—Å—Ç –ª–æ–≥–∞:")
    pprint(_tail_log(6))

# ---------- –°—Ü–µ–Ω–∞—Ä–∏–π 3: –ü–æ—Ç–µ—Ä—è –º–æ—Ç–∏–≤–∞—Ü–∏–∏ ----------
def scenario_low_motivation():
    _print_header("–°—Ü–µ–Ω–∞—Ä–∏–π 3: –ø–∞–¥–µ–Ω–∏–µ –º–æ—Ç–∏–≤–∞—Ü–∏–∏")
    _reset_for_scenario()

    # 1) –¥–ª–∏–Ω–Ω–∞—è –ø–∞—É–∑–∞/–Ω–∏–∑–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ (–∏–º–∏—Ç–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ Expert‚Äë–º–µ—Ç—Ä–∏–∫–∏)
    ex = ctx.progress.setdefault("Expert", {})
    ex["engagement"] = 0.32
    ex["confidence"] = 0.28
    ex["latency_sec"] = 50.0  # –ò–º–∏—Ç–∏—Ä—É–µ–º –º–µ–¥–ª–µ–Ω–Ω—ã–π –æ—Ç–∫–ª–∏–∫ (—É—á—Ç—ë—Ç—Å—è Motivator-–æ–º)

    # 2) –∫–æ—Ä–æ—Ç–∫–∏–µ/–Ω–µ—É–≤–µ—Ä–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
    for q in ["–î–∞", "–ù–µ –ø–æ–Ω–∏–º–∞—é", "–•–º‚Ä¶"]:
        bus.publish(Event(type="student_question", source="student", payload={"text": q}))
        time.sleep(0.05)

    mot = _mot()
    print("–°—Ç–∞–¥–∏—è:", _stage())
    print("–û—Ç–≤–µ—Ç–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–∞:", _answers_count())
    print("Motivator level:", mot.get("level"), mot.get("level_name"))
    print("–°–∏–≥–Ω–∞–ª—ã:", mot.get("signals"))
    print("–†–µ–∞–∫—Ü–∏—è:", mot.get("reaction"))
    print("–°—Ç–∏–ª—å –±–∞–∑–æ–≤—ã–π:", mot.get("style"))
    print("–°—Ç–∏–ª—å update:", mot.get("style_update"))
    print("–°—á—ë—Ç—á–∏–∫ –ø–∞–¥–µ–Ω–∏–π:", mot.get("drop_count"))
    print("–•–≤–æ—Å—Ç –ª–æ–≥–∞:")
    pprint(_tail_log(6))

# ---------- –°—Ü–µ–Ω–∞—Ä–∏–π 4: –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –ø–∞—Ä—ã ----------
def scenario_restart():
    _print_header("–°—Ü–µ–Ω–∞—Ä–∏–π 4: –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫")
    _reset_for_scenario()

    # –ù–µ–º–Ω–æ–≥–æ ¬´—Ä–∞–±–æ—Ç—ã¬ª
    bus.publish(Event(type="student_question", source="student", payload={"text": "–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å –ª–µ–≥–µ–Ω–¥—É –∫ –¥–∏–∞–≥—Ä–∞–º–º–µ?"}))
    time.sleep(0.05)

    # –ß–∞—Å—Ç–∏—á–Ω—ã–π —Ä–µ—Å—Ç–∞—Ä—Ç —Ç–µ–∫—É—â–µ–≥–æ —ç—Ç–∞–ø–∞
    bus.publish(Event(type="restart", source="tester", payload={"mode": "stage", "reason": "retry_current"}))
    time.sleep(0.05)
    bus.publish(Event(type="student_question", source="student", payload={"text": "–ï—â—ë —Ä–∞–∑: –≥–¥–µ –ø–æ–¥–ø–∏—Å—ã–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è?"}))
    time.sleep(0.05)

    # –ü–æ–ª–Ω—ã–π —Ä–µ—Å—Ç–∞—Ä—Ç —Å –Ω–∞—á–∞–ª–∞
    bus.publish(Event(type="restart", source="tester", payload={"mode": "full", "reason": "not_understood"}))
    time.sleep(0.05)
    bus.publish(Event(type="student_question", source="student", payload={"text": "–ü–æ–≤—Ç–æ—Ä–∏ –∫—Ä–∞—Ç–∫–æ —Ü–µ–ª–∏ –∑–∞–Ω—è—Ç–∏—è, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞."}))
    time.sleep(0.05)

    print("–°—Ç–∞–¥–∏—è:", _stage())
    print("–û—Ç–≤–µ—Ç–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–∞:", _answers_count())
    print("Motivator level:", _mot().get("level"), _mot().get("level_name"))
    print("–•–≤–æ—Å—Ç –ª–æ–≥–∞:")
    pprint(_tail_log(8))

# ---------- –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö ----------
def run_all_scenarios():
    print("‚ÑπÔ∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º ctx/expert/bus/conductor (–∏ motivator/organizer, –µ—Å–ª–∏ –µ—Å—Ç—å).")
    scenario_smooth()
    scenario_mistakes()
    scenario_low_motivation()
    scenario_restart()

# ‚ñ∂Ô∏è –ó–∞–ø—É—Å–∫
run_all_scenarios()
paths = export_eventbus_logs(ctx)
paths

print("üéØ –ú–∏–Ω–∏‚Äë—Ç–µ—Å—Ç TTS-–ø–∞–π–ø–ª–∞–π–Ω–∞")
bus.publish(Event(type="student_question", source="student", payload={"text": "–ö–∞–∫ –≤—ã–±—Ä–∞—Ç—å —Ç–∏–ø –¥–∏–∞–≥—Ä–∞–º–º—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è?"}))
time.sleep(0.1)

# –ø–æ—Å–º–æ—Ç—Ä–∏–º —Ö–≤–æ—Å—Ç event-–ª–æ–≥–∞
from pprint import pprint
print("\nüìú –•–≤–æ—Å—Ç EventBus:")
pprint(ctx.progress["EventBus"]["log"][-6:])

# –∏ —á—Ç–æ —Å–æ—Ö—Ä–∞–Ω–∏–ª TTS
print("\nüóÇ –ü—Ä–∏–º–µ—Ä –∑–∞–ø–∏—Å–∏ –≤ TTS cache (–µ—Å–ª–∏ –±—ã–ª–∞ –∫–æ—Ä–æ—Ç–∫–∞—è —Ñ—Ä–∞–∑–∞):")
print(list(ctx.progress.get("TTS", {}).get("cache", {}).keys())[:2])

# —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–æ—Ä–æ–∂–∫—É:
# –æ—Ç–∫—Ä–æ–π –ø—É—Ç—å –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ tts_done (–µ—Å–ª–∏ –ª–æ–≥–∏—Ä—É–µ—à—å payload –≥–¥–µ-—Ç–æ)